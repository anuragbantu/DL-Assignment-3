{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11812889,"sourceType":"datasetVersion","datasetId":7419453}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:34.258037Z","iopub.execute_input":"2025-05-19T09:28:34.258727Z","iopub.status.idle":"2025-05-19T09:28:34.576314Z","shell.execute_reply.started":"2025-05-19T09:28:34.258692Z","shell.execute_reply":"2025-05-19T09:28:34.575553Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/telugu-lexicon/te.translit.sampled.train.tsv\n/kaggle/input/telugu-lexicon/te.translit.sampled.dev.tsv\n/kaggle/input/telugu-lexicon/te.translit.sampled.test.tsv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n# Load data\ntrain_df = pd.read_csv(\"/kaggle/input/telugu-lexicon/te.translit.sampled.train.tsv\", sep=\"\\t\", header=None)\ntrain_df.columns = [\"target\", \"source\", \"label\"]\n#pairs = list(zip(train_df[\"source\"], train_df[\"target\"]))  # Latin to Devanagari\n\n# Preview\n\nval_df = pd.read_csv(\"/kaggle/input/telugu-lexicon/te.translit.sampled.dev.tsv\", sep=\"\\t\", header=None)\nval_df.columns = [\"target\", \"source\", \"label\"]\n#val_pairs = list(zip(val_df[\"source\"], val_df[\"target\"]))\n\n# Drop any rows where source or target is missing\ntrain_df = train_df.dropna(subset=[\"source\", \"target\"])\nval_df = val_df.dropna(subset=[\"source\", \"target\"])\n\n# Ensure source and target are strings\ntrain_df[\"source\"] = train_df[\"source\"].astype(str)\ntrain_df[\"target\"] = train_df[\"target\"].astype(str)\nval_df[\"source\"] = val_df[\"source\"].astype(str)\nval_df[\"target\"] = val_df[\"target\"].astype(str)\n\n# Create pairs\npairs = list(zip(train_df[\"source\"], train_df[\"target\"]))\nval_pairs = list(zip(val_df[\"source\"], val_df[\"target\"]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:34.577732Z","iopub.execute_input":"2025-05-19T09:28:34.578076Z","iopub.status.idle":"2025-05-19T09:28:34.693826Z","shell.execute_reply.started":"2025-05-19T09:28:34.578058Z","shell.execute_reply":"2025-05-19T09:28:34.693310Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"print(len(val_pairs))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:34.694515Z","iopub.execute_input":"2025-05-19T09:28:34.694730Z","iopub.status.idle":"2025-05-19T09:28:34.699070Z","shell.execute_reply.started":"2025-05-19T09:28:34.694713Z","shell.execute_reply":"2025-05-19T09:28:34.698168Z"}},"outputs":[{"name":"stdout","text":"5683\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import random\n\nsample_size = 10000\npairs = random.sample(pairs, sample_size)    # use only 2000 training samples\n#val_pairs = random.sample(val_pairs, sample_size) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:34.700607Z","iopub.execute_input":"2025-05-19T09:28:34.700830Z","iopub.status.idle":"2025-05-19T09:28:34.718596Z","shell.execute_reply.started":"2025-05-19T09:28:34.700809Z","shell.execute_reply":"2025-05-19T09:28:34.717911Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:34.719263Z","iopub.execute_input":"2025-05-19T09:28:34.719455Z","iopub.status.idle":"2025-05-19T09:28:36.366700Z","shell.execute_reply.started":"2025-05-19T09:28:34.719441Z","shell.execute_reply":"2025-05-19T09:28:36.366110Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#pairs = list(zip(df[\"source\"], df[\"target\"]))\n\n#pairs = [\n #   (\"namaste\", \"नमस्ते\"),\n  #  (\"bharat\",  \"भारत\"),\n   # (\"duniya\",  \"दुनिया\"),\n    #(\"prem\",    \"प्रेम\"),\n#]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:36.367376Z","iopub.execute_input":"2025-05-19T09:28:36.367680Z","iopub.status.idle":"2025-05-19T09:28:36.371123Z","shell.execute_reply.started":"2025-05-19T09:28:36.367663Z","shell.execute_reply":"2025-05-19T09:28:36.370518Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"SRC_CHARS = set(\"\".join(s for s, _ in pairs))\nTRG_CHARS = set(\"\".join(t for _, t in pairs)) | {\"<sos>\", \"<eos>\"}\n\nsrc2idx = {ch: i+1 for i, ch in enumerate(sorted(SRC_CHARS))}  # reserve 0 for padding\nsrc2idx[\"<pad>\"] = 0\ntrg2idx = {ch: i+1 for i, ch in enumerate(sorted(TRG_CHARS))}\ntrg2idx[\"<pad>\"] = 0\n\nidx2trg = {i: ch for ch, i in trg2idx.items()}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:36.371902Z","iopub.execute_input":"2025-05-19T09:28:36.372185Z","iopub.status.idle":"2025-05-19T09:28:36.400968Z","shell.execute_reply.started":"2025-05-19T09:28:36.372160Z","shell.execute_reply":"2025-05-19T09:28:36.400290Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n# === RNN Cell Wrapper === #\ndef get_rnn_cell(cell_type):\n    cell_type = cell_type.upper()\n    if cell_type == \"GRU\":\n        return nn.GRU\n    elif cell_type == \"LSTM\":\n        return nn.LSTM\n    elif cell_type == \"RNN\":\n        return nn.RNN\n    else:\n        raise ValueError(\"Unsupported RNN cell type. Use 'RNN', 'GRU', or 'LSTM'.\")\n\n# === Encoder === #\nclass Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, hidden_dim, cell_type=\"GRU\", num_layers=1, dropout=0.0):\n        super().__init__()\n        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=0)\n        self.rnn = get_rnn_cell(cell_type)(\n            emb_dim, hidden_dim, num_layers, dropout=dropout if num_layers > 1 else 0.0\n        )\n    def forward(self, src):\n        embedded = self.embedding(src)  # [src_len, batch=1, emb_dim]\n        outputs, hidden = self.rnn(embedded)  # hidden: [num_layers, batch, hidden_dim]\n        return hidden\n\n# === Decoder === #\nclass Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, hidden_dim, cell_type=\"GRU\", num_layers=1, dropout=0.0):\n        super().__init__()\n        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=0)\n        self.rnn = get_rnn_cell(cell_type)(\n            emb_dim, hidden_dim, num_layers, dropout=dropout if num_layers > 1 else 0.0\n        )\n        self.out = nn.Linear(hidden_dim, output_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, input_step, hidden):\n        embedded = self.embedding(input_step)  # [1, 1, emb_dim]\n        output, hidden = self.rnn(embedded, hidden)\n        output = self.dropout(output.squeeze(0))  # Apply dropout to RNN output\n        prediction = self.out(output)             # [1, output_dim]\n        return prediction, hidden\n\n# === Seq2Seq Wrapper === #\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device, sos_idx):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n        self.sos_idx = sos_idx\n\n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        trg_len = trg.shape[0]\n        output_dim = self.decoder.out.out_features\n        outputs = torch.zeros(trg_len, 1, output_dim).to(self.device)\n\n        hidden = self.encoder(src)\n        hidden = self.adjust_hidden_for_decoder(hidden, self.decoder.rnn.num_layers)\n\n        input_step = torch.tensor([[self.sos_idx]], device=self.device)\n\n        for t in range(trg_len):\n            output, hidden = self.decoder(input_step, hidden)\n            outputs[t] = output\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = output.argmax(1).unsqueeze(0)\n            input_step = trg[t].unsqueeze(0) if teacher_force else top1\n\n        return outputs\n\n    def adjust_hidden_for_decoder(self, hidden, target_layers):\n        \"\"\"\n        Adjust the encoder's hidden state to match the number of decoder layers.\n        Pads if encoder has fewer layers, trims if more.\n        Works for GRU/RNN (tensor) and LSTM (tuple).\n        \"\"\"\n        if isinstance(hidden, tuple):  # LSTM\n            h, c = hidden\n            h = self._match_layers(h, target_layers)\n            c = self._match_layers(c, target_layers)\n            return (h, c)\n        else:  # GRU or RNN\n            return self._match_layers(hidden, target_layers)\n\n    def _match_layers(self, state, target_layers):\n        \"\"\"\n        Pad or trim the hidden state tensor to match target number of layers.\n        \"\"\"\n        current_layers = state.size(0)\n        if current_layers == target_layers:\n            return state\n        elif current_layers < target_layers:\n            diff = target_layers - current_layers\n            pad = torch.zeros(diff, state.size(1), state.size(2), device=state.device)\n            return torch.cat([state, pad], dim=0)\n        else:  # current_layers > target_layers\n            return state[:target_layers]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:36.401669Z","iopub.execute_input":"2025-05-19T09:28:36.401851Z","iopub.status.idle":"2025-05-19T09:28:36.414709Z","shell.execute_reply.started":"2025-05-19T09:28:36.401836Z","shell.execute_reply":"2025-05-19T09:28:36.414192Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"emb_dim = 64\nhidden_dim = 128\ncell_type = \"RNN\"  # or \"GRU\", \"RNN\"\nnum_layers = 2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:36.415414Z","iopub.execute_input":"2025-05-19T09:28:36.415649Z","iopub.status.idle":"2025-05-19T09:28:36.432608Z","shell.execute_reply.started":"2025-05-19T09:28:36.415624Z","shell.execute_reply":"2025-05-19T09:28:36.431914Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:36.435155Z","iopub.execute_input":"2025-05-19T09:28:36.435365Z","iopub.status.idle":"2025-05-19T09:28:36.495935Z","shell.execute_reply.started":"2025-05-19T09:28:36.435351Z","shell.execute_reply":"2025-05-19T09:28:36.495188Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"'''\nimport torch.optim as optim\n\nencoder = Encoder(len(src2idx), emb_dim, hidden_dim, cell_type, num_layers)\ndecoder = Decoder(len(trg2idx), emb_dim, hidden_dim, cell_type, num_layers)\nsos_idx = trg2idx[\"<sos>\"]\nmodel = Seq2Seq(encoder, decoder, DEVICE, sos_idx).to(DEVICE)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss(ignore_index=trg2idx[\"<pad>\"])\n'''\ndef tensor_from_word(word, mapping, add_eos=False):\n    indices = [mapping[ch] for ch in word]\n    if add_eos:\n        indices.append(mapping[\"<eos>\"])\n    return torch.tensor(indices, dtype=torch.long, device=DEVICE).unsqueeze(1)\n\n'''\nfor epoch in range(1, 6):\n    model.train()\n    epoch_loss = 0\n    train_correct = 0\n    train_total = 0\n\n    for src_word, trg_word in pairs:\n        src_tensor = tensor_from_word(src_word, src2idx)\n        trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n        optimizer.zero_grad()\n        output = model(src_tensor, trg_tensor)\n        output_dim = output.shape[-1]\n        loss = criterion(output.view(-1, output_dim), trg_tensor.view(-1))\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n\n        # Training accuracy\n        pred_tokens = output.argmax(-1).view(-1)\n        true_tokens = trg_tensor.view(-1)\n        mask = true_tokens != trg2idx[\"<pad>\"]\n        correct = (pred_tokens == true_tokens) & mask\n        train_correct += correct.sum().item()\n        train_total += mask.sum().item()\n\n    # Validation\n    model.eval()\n    val_loss = 0\n    val_correct = 0\n    val_total = 0\n    with torch.no_grad():\n        for src_word, trg_word in val_pairs:\n            src_tensor = tensor_from_word(src_word, src2idx)\n            trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n            output = model(src_tensor, trg_tensor)\n            loss = criterion(output.view(-1, output.shape[-1]), trg_tensor.view(-1))\n            val_loss += loss.item()\n\n            pred_tokens = output.argmax(-1).view(-1)\n            true_tokens = trg_tensor.view(-1)\n            mask = true_tokens != trg2idx[\"<pad>\"]\n            correct = (pred_tokens == true_tokens) & mask\n            val_correct += correct.sum().item()\n            val_total += mask.sum().item()\n\n    train_acc = train_correct / train_total\n    val_acc = val_correct / val_total\n    print(f\"Epoch {epoch:3d} | Train Loss: {epoch_loss/len(pairs):.4f} | \"\n          f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_pairs):.4f} | Val Acc: {val_acc:.4f}\")\n\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:36.496722Z","iopub.execute_input":"2025-05-19T09:28:36.496954Z","iopub.status.idle":"2025-05-19T09:28:36.517913Z","shell.execute_reply.started":"2025-05-19T09:28:36.496936Z","shell.execute_reply":"2025-05-19T09:28:36.517279Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'\\nfor epoch in range(1, 6):\\n    model.train()\\n    epoch_loss = 0\\n    train_correct = 0\\n    train_total = 0\\n\\n    for src_word, trg_word in pairs:\\n        src_tensor = tensor_from_word(src_word, src2idx)\\n        trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\\n\\n        optimizer.zero_grad()\\n        output = model(src_tensor, trg_tensor)\\n        output_dim = output.shape[-1]\\n        loss = criterion(output.view(-1, output_dim), trg_tensor.view(-1))\\n        loss.backward()\\n        optimizer.step()\\n        epoch_loss += loss.item()\\n\\n        # Training accuracy\\n        pred_tokens = output.argmax(-1).view(-1)\\n        true_tokens = trg_tensor.view(-1)\\n        mask = true_tokens != trg2idx[\"<pad>\"]\\n        correct = (pred_tokens == true_tokens) & mask\\n        train_correct += correct.sum().item()\\n        train_total += mask.sum().item()\\n\\n    # Validation\\n    model.eval()\\n    val_loss = 0\\n    val_correct = 0\\n    val_total = 0\\n    with torch.no_grad():\\n        for src_word, trg_word in val_pairs:\\n            src_tensor = tensor_from_word(src_word, src2idx)\\n            trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\\n            output = model(src_tensor, trg_tensor)\\n            loss = criterion(output.view(-1, output.shape[-1]), trg_tensor.view(-1))\\n            val_loss += loss.item()\\n\\n            pred_tokens = output.argmax(-1).view(-1)\\n            true_tokens = trg_tensor.view(-1)\\n            mask = true_tokens != trg2idx[\"<pad>\"]\\n            correct = (pred_tokens == true_tokens) & mask\\n            val_correct += correct.sum().item()\\n            val_total += mask.sum().item()\\n\\n    train_acc = train_correct / train_total\\n    val_acc = val_correct / val_total\\n    print(f\"Epoch {epoch:3d} | Train Loss: {epoch_loss/len(pairs):.4f} | \"\\n          f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_pairs):.4f} | Val Acc: {val_acc:.4f}\")\\n\\n'"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"def beam_search(model, src_tensor, beam_size=3, max_len=30):\n    model.eval()\n    with torch.no_grad():\n        hidden = model.encoder(src_tensor)\n        hidden = model.adjust_hidden_for_decoder(hidden, model.decoder.rnn.num_layers)\n\n\n        if isinstance(hidden, tuple):\n            h, c = hidden\n            hidden = (\n                h[:model.decoder.rnn.num_layers],\n                c[:model.decoder.rnn.num_layers],\n            )\n        else:\n            hidden = hidden[:model.decoder.rnn.num_layers]\n\n        sequences = [([model.sos_idx], 0.0, hidden)]\n\n        for _ in range(max_len):\n            all_candidates = []\n            for seq, score, h in sequences:\n                input_step = torch.tensor([[seq[-1]]], device=model.device)\n                output, h_new = model.decoder(input_step, h)\n                probs = torch.log_softmax(output, dim=1)\n                topk = torch.topk(probs, beam_size)\n\n                for i in range(beam_size):\n                    token = topk.indices[0][i].item()\n                    token_score = topk.values[0][i].item()\n                    new_seq = seq + [token]\n                    all_candidates.append((new_seq, score + token_score, h_new))\n\n            sequences = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_size]\n\n            if all(seq[-1] == trg2idx[\"<eos>\"] for seq, _, _ in sequences):\n                break\n\n        best_seq = sequences[0][0][1:]  # remove <sos>\n        return \"\".join([idx2trg[i] for i in best_seq if i != trg2idx[\"<eos>\"]])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:36.518632Z","iopub.execute_input":"2025-05-19T09:28:36.518839Z","iopub.status.idle":"2025-05-19T09:28:36.536007Z","shell.execute_reply.started":"2025-05-19T09:28:36.518815Z","shell.execute_reply":"2025-05-19T09:28:36.535338Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"!pip install -q wandb\nimport wandb\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:36.536765Z","iopub.execute_input":"2025-05-19T09:28:36.536965Z","iopub.status.idle":"2025-05-19T09:28:40.666408Z","shell.execute_reply.started":"2025-05-19T09:28:36.536950Z","shell.execute_reply":"2025-05-19T09:28:40.665802Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"wandb.login(key='af7d7cf29d8954a13afb06c7a0d0c196c36ac51b')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:40.667106Z","iopub.execute_input":"2025-05-19T09:28:40.667440Z","iopub.status.idle":"2025-05-19T09:28:46.768361Z","shell.execute_reply.started":"2025-05-19T09:28:40.667420Z","shell.execute_reply":"2025-05-19T09:28:46.767599Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma24m003\u001b[0m (\u001b[33mma24m003-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"sweep_config = {\n    \"method\": \"bayes\",\n    \"metric\": {\"name\": \"val_acc\", \"goal\": \"maximize\"},\n    \"parameters\": {\n        \"emb_dim\": {\"values\": [16,32,64,256]},\n        \"hidden_dim\": {\"values\": [16,32,64,256]},\n        \"cell_type\": {\"values\": [\"RNN\",\"GRU\",\"LSTM\"]},\n        \"enc_layers\": {\"values\": [1,2,3]},\n        \"dec_layers\": {\"values\": [1, 2, 3]},\n        \"dropout\": {\"values\": [0,0.2, 0.3]},\n        \"beam_size\": {\"values\": [1, 3, 2]},\n        \"lr\": {\"values\": [0.001, 0.0005]},\n        \"teacher_forcing_ratio\": {\"values\": [0.3, 0.5, 0.7, 1.0]}\n\n    }\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:46.769191Z","iopub.execute_input":"2025-05-19T09:28:46.769612Z","iopub.status.idle":"2025-05-19T09:28:46.774571Z","shell.execute_reply.started":"2025-05-19T09:28:46.769594Z","shell.execute_reply":"2025-05-19T09:28:46.773864Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def train_model(config=None):\n    with wandb.init(config=config) as run:\n        config = wandb.config\n\n        run.name = f\"emb{config.emb_dim}_hid{config.hidden_dim}_{config.cell_type}_enc{config.enc_layers}_dec{config.dec_layers}_drop{int(config.dropout*100)}_beam{config.beam_size}_lr{config.lr}\"\n\n        encoder = Encoder(len(src2idx), config.emb_dim, config.hidden_dim,\n                          config.cell_type, config.enc_layers, config.dropout)\n        decoder = Decoder(len(trg2idx), config.emb_dim, config.hidden_dim,\n                          config.cell_type, config.dec_layers, config.dropout)\n        model = Seq2Seq(encoder, decoder, DEVICE, sos_idx=trg2idx[\"<sos>\"]).to(DEVICE)\n\n        optimizer = optim.Adam(model.parameters(), lr=config.lr)\n        criterion = nn.CrossEntropyLoss(ignore_index=trg2idx[\"<pad>\"])\n        beam_size = config.get(\"beam_size\", 3)\n\n        for epoch in range(1, 6):\n            model.train()\n            total_loss = 0\n            train_correct = 0\n            train_total = 0\n\n            for src_word, trg_word in pairs:\n                src_tensor = tensor_from_word(src_word, src2idx)\n                trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n                optimizer.zero_grad()\n                output = model(src_tensor, trg_tensor, teacher_forcing_ratio=config.get(\"teacher_forcing_ratio\", 0.5))\n                loss = criterion(output.view(-1, output.size(-1)), trg_tensor.view(-1))\n                loss.backward()\n                optimizer.step()\n                total_loss += loss.item()\n\n                pred_tokens = output.argmax(-1).view(-1)\n                true_tokens = trg_tensor.view(-1)\n                mask = true_tokens != trg2idx[\"<pad>\"]\n                correct = (pred_tokens == true_tokens) & mask\n                train_correct += correct.sum().item()\n                train_total += mask.sum().item()\n\n            model.eval()\n            val_loss = 0\n            val_correct = 0\n            val_total = 0\n            exact_match_count = 0\n\n            with torch.no_grad():\n                for src_word, trg_word in val_pairs:\n                    src_tensor = tensor_from_word(src_word, src2idx)\n                    trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n                    output = model(src_tensor, trg_tensor, teacher_forcing_ratio=0.0)\n                    loss = criterion(output.view(-1, output.size(-1)), trg_tensor.view(-1))\n                    val_loss += loss.item()\n\n                    pred_tokens = output.argmax(-1).view(-1)\n                    true_tokens = trg_tensor.view(-1)\n                    mask = true_tokens != trg2idx[\"<pad>\"]\n                    correct = (pred_tokens == true_tokens) & mask\n                    val_correct += correct.sum().item()\n                    val_total += mask.sum().item()\n\n                    # Beam search for exact match accuracy\n                    pred_str = beam_search(model, src_tensor, beam_size=beam_size)\n                    if pred_str == trg_word:\n                        exact_match_count += 1\n\n            train_acc = train_correct / train_total\n            val_acc = val_correct / val_total\n            exact_match = exact_match_count / len(val_pairs)\n            \n            print(f\"Epoch {epoch:2d} | \"\n                  f\"Train Loss: {total_loss / len(pairs):.4f} | \"\n                  f\"Train Acc: {train_acc:.4f} | \"\n                  f\"Val Loss: {val_loss / len(val_pairs):.4f} | \"\n                  f\"Val Acc: {val_acc:.4f} | \"\n                  f\"Val Exact Match: {exact_match:.4f} | \"\n                  f\"Beam Size: {beam_size}\")\n\n            \n            wandb.log({\n                \"epoch\": epoch,\n                \"train_loss\": total_loss / len(pairs),\n                \"val_loss\": val_loss / len(val_pairs),\n                \"train_accuracy\": train_correct / train_total,\n                \"val_accuracy\": val_correct / val_total,\n                \"val_exact_match\": exact_match_count / len(val_pairs),\n                \"beam_size\": beam_size\n            })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:46.775387Z","iopub.execute_input":"2025-05-19T09:28:46.775672Z","iopub.status.idle":"2025-05-19T09:28:46.794205Z","shell.execute_reply.started":"2025-05-19T09:28:46.775646Z","shell.execute_reply":"2025-05-19T09:28:46.793515Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"'''\nsweep_id = wandb.sweep(sweep_config, project=\"transliteration-sweep\")\nwandb.agent(sweep_id, function=train_model, count=100)\nwandb.finish()\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:46.794813Z","iopub.execute_input":"2025-05-19T09:28:46.795285Z","iopub.status.idle":"2025-05-19T09:28:46.812576Z","shell.execute_reply.started":"2025-05-19T09:28:46.795266Z","shell.execute_reply":"2025-05-19T09:28:46.812011Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'\\nsweep_id = wandb.sweep(sweep_config, project=\"transliteration-sweep\")\\nwandb.agent(sweep_id, function=train_model, count=100)\\nwandb.finish()\\n'"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"best_config = {\n    \"emb_dim\": 32,\n    \"hidden_dim\": 256,\n    \"cell_type\": \"LSTM\",\n    \"enc_layers\": 3,\n    \"dec_layers\": 2,\n    \"dropout\": 0,\n    \"beam_size\": 3,\n    \"lr\": 0.001}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:46.813262Z","iopub.execute_input":"2025-05-19T09:28:46.813467Z","iopub.status.idle":"2025-05-19T09:28:46.828865Z","shell.execute_reply.started":"2025-05-19T09:28:46.813453Z","shell.execute_reply":"2025-05-19T09:28:46.828146Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def best_train_model(config=None):\n    with wandb.init(config=config):\n        config = wandb.config\n\n        encoder = Encoder(len(src2idx), config.emb_dim, config.hidden_dim,\n                          config.cell_type, config.enc_layers, config.dropout)\n        decoder = Decoder(len(trg2idx), config.emb_dim, config.hidden_dim,\n                          config.cell_type, config.dec_layers, config.dropout)\n        model = Seq2Seq(encoder, decoder, DEVICE, sos_idx=trg2idx[\"<sos>\"]).to(DEVICE)\n\n        optimizer = optim.Adam(model.parameters(), lr=config.lr)\n        criterion = nn.CrossEntropyLoss(ignore_index=trg2idx[\"<pad>\"])\n        beam_size = config.get(\"beam_size\", 3)\n\n        for epoch in range(1, 11):\n            model.train()\n            total_loss = 0\n            train_correct = 0\n            train_total = 0\n\n            for src_word, trg_word in pairs:\n                src_tensor = tensor_from_word(src_word, src2idx)\n                trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n                optimizer.zero_grad()\n                output = model(src_tensor, trg_tensor, teacher_forcing_ratio=config.get(\"teacher_forcing_ratio\", 0.5))\n                loss = criterion(output.view(-1, output.size(-1)), trg_tensor.view(-1))\n                loss.backward()\n                optimizer.step()\n                total_loss += loss.item()\n\n                pred_tokens = output.argmax(-1).view(-1)\n                true_tokens = trg_tensor.view(-1)\n                mask = true_tokens != trg2idx[\"<pad>\"]\n                correct = (pred_tokens == true_tokens) & mask\n                train_correct += correct.sum().item()\n                train_total += mask.sum().item()\n\n            model.eval()\n            val_loss = 0\n            val_correct = 0\n            val_total = 0\n            exact_match_count = 0\n\n            with torch.no_grad():\n                for src_word, trg_word in val_pairs:\n                    src_tensor = tensor_from_word(src_word, src2idx)\n                    trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n                    output = model(src_tensor, trg_tensor, teacher_forcing_ratio=0.0)\n                    loss = criterion(output.view(-1, output.size(-1)), trg_tensor.view(-1))\n                    val_loss += loss.item()\n\n                    pred_tokens = output.argmax(-1).view(-1)\n                    true_tokens = trg_tensor.view(-1)\n                    mask = true_tokens != trg2idx[\"<pad>\"]\n                    correct = (pred_tokens == true_tokens) & mask\n                    val_correct += correct.sum().item()\n                    val_total += mask.sum().item()\n\n                    # Beam search for exact match accuracy\n                    pred_str = beam_search(model, src_tensor, beam_size=beam_size)\n                    if pred_str == trg_word:\n                        exact_match_count += 1\n\n            train_acc = train_correct / train_total\n            val_acc = val_correct / val_total\n            exact_match = exact_match_count / len(val_pairs)\n\n            print(f\"Epoch {epoch:2d} | \"\n                  f\"Train Loss: {total_loss / len(pairs):.4f} | \"\n                  f\"Train Acc: {train_acc:.4f} | \"\n                  f\"Val Loss: {val_loss / len(val_pairs):.4f} | \"\n                  f\"Val Acc: {val_acc:.4f} | \"\n                  f\"Val Exact Match: {exact_match:.4f} | \"\n                  f\"Beam Size: {beam_size}\")\n\n            wandb.log({\n                \"epoch\": epoch,\n                \"train_loss\": total_loss / len(pairs),\n                \"val_loss\": val_loss / len(val_pairs),\n                \"train_accuracy\": train_acc,\n                \"val_accuracy\": val_acc,\n                \"val_exact_match\": exact_match,\n                \"beam_size\": beam_size\n            })\n\n        return model  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:46.829626Z","iopub.execute_input":"2025-05-19T09:28:46.829815Z","iopub.status.idle":"2025-05-19T09:28:46.842620Z","shell.execute_reply.started":"2025-05-19T09:28:46.829799Z","shell.execute_reply":"2025-05-19T09:28:46.841918Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"model = best_train_model(config=best_config)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T09:28:46.843382Z","iopub.execute_input":"2025-05-19T09:28:46.843570Z","iopub.status.idle":"2025-05-19T10:15:13.971617Z","shell.execute_reply.started":"2025-05-19T09:28:46.843556Z","shell.execute_reply":"2025-05-19T10:15:13.971065Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250519_092846-hylvxdx4</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma24m003-iit-madras/uncategorized/runs/hylvxdx4' target=\"_blank\">fancy-paper-36</a></strong> to <a href='https://wandb.ai/ma24m003-iit-madras/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma24m003-iit-madras/uncategorized' target=\"_blank\">https://wandb.ai/ma24m003-iit-madras/uncategorized</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma24m003-iit-madras/uncategorized/runs/hylvxdx4' target=\"_blank\">https://wandb.ai/ma24m003-iit-madras/uncategorized/runs/hylvxdx4</a>"},"metadata":{}},{"name":"stdout","text":"Epoch  1 | Train Loss: 1.7989 | Train Acc: 0.4938 | Val Loss: 1.2788 | Val Acc: 0.6081 | Val Exact Match: 0.1438 | Beam Size: 3\nEpoch  2 | Train Loss: 0.7570 | Train Acc: 0.7686 | Val Loss: 1.0283 | Val Acc: 0.7098 | Val Exact Match: 0.2715 | Beam Size: 3\nEpoch  3 | Train Loss: 0.5161 | Train Acc: 0.8435 | Val Loss: 1.0111 | Val Acc: 0.7326 | Val Exact Match: 0.3276 | Beam Size: 3\nEpoch  4 | Train Loss: 0.3873 | Train Acc: 0.8826 | Val Loss: 1.0115 | Val Acc: 0.7488 | Val Exact Match: 0.3422 | Beam Size: 3\nEpoch  5 | Train Loss: 0.2972 | Train Acc: 0.9096 | Val Loss: 1.0784 | Val Acc: 0.7466 | Val Exact Match: 0.3005 | Beam Size: 3\nEpoch  6 | Train Loss: 0.2383 | Train Acc: 0.9269 | Val Loss: 1.1256 | Val Acc: 0.7471 | Val Exact Match: 0.2942 | Beam Size: 3\nEpoch  7 | Train Loss: 0.2069 | Train Acc: 0.9362 | Val Loss: 1.1616 | Val Acc: 0.7478 | Val Exact Match: 0.3338 | Beam Size: 3\nEpoch  8 | Train Loss: 0.1856 | Train Acc: 0.9418 | Val Loss: 1.1803 | Val Acc: 0.7543 | Val Exact Match: 0.3335 | Beam Size: 3\nEpoch  9 | Train Loss: 0.1725 | Train Acc: 0.9469 | Val Loss: 1.2311 | Val Acc: 0.7502 | Val Exact Match: 0.3637 | Beam Size: 3\nEpoch 10 | Train Loss: 0.1515 | Train Acc: 0.9538 | Val Loss: 1.3030 | Val Acc: 0.7474 | Val Exact Match: 0.3449 | Beam Size: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>beam_size</td><td>▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▅▆▇▇█████</td></tr><tr><td>train_loss</td><td>█▄▃▂▂▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▆▇███████</td></tr><tr><td>val_exact_match</td><td>▁▅▇▇▆▆▇▇█▇</td></tr><tr><td>val_loss</td><td>▇▁▁▁▃▄▅▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>beam_size</td><td>3</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>train_accuracy</td><td>0.95377</td></tr><tr><td>train_loss</td><td>0.15146</td></tr><tr><td>val_accuracy</td><td>0.74742</td></tr><tr><td>val_exact_match</td><td>0.34489</td></tr><tr><td>val_loss</td><td>1.30296</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">fancy-paper-36</strong> at: <a href='https://wandb.ai/ma24m003-iit-madras/uncategorized/runs/hylvxdx4' target=\"_blank\">https://wandb.ai/ma24m003-iit-madras/uncategorized/runs/hylvxdx4</a><br> View project at: <a href='https://wandb.ai/ma24m003-iit-madras/uncategorized' target=\"_blank\">https://wandb.ai/ma24m003-iit-madras/uncategorized</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250519_092846-hylvxdx4/logs</code>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"\ntest_df = pd.read_csv(\"/kaggle/input/telugu-lexicon/te.translit.sampled.test.tsv\", sep=\"\\t\", header=None)\ntest_df.columns = [\"target\", \"source\", \"label\"]  # adjust if only 2 columns\ntest_df = test_df.dropna(subset=[\"source\", \"target\"])\ntest_df[\"source\"] = test_df[\"source\"].astype(str)\ntest_df[\"target\"] = test_df[\"target\"].astype(str)\ntest_pairs = list(zip(test_df[\"source\"], test_df[\"target\"]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T10:15:13.972625Z","iopub.execute_input":"2025-05-19T10:15:13.973241Z","iopub.status.idle":"2025-05-19T10:15:14.020063Z","shell.execute_reply.started":"2025-05-19T10:15:13.973222Z","shell.execute_reply":"2025-05-19T10:15:14.019353Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"print(len(test_pairs))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T10:15:14.020876Z","iopub.execute_input":"2025-05-19T10:15:14.021077Z","iopub.status.idle":"2025-05-19T10:15:14.025097Z","shell.execute_reply.started":"2025-05-19T10:15:14.021062Z","shell.execute_reply":"2025-05-19T10:15:14.024585Z"}},"outputs":[{"name":"stdout","text":"5747\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"model.eval()\ntest_correct = 0\ntest_total = 0\nexact_match_count = 0\nbeam_size = best_config[\"beam_size\"]\n\nwith torch.no_grad():\n    for src_word, trg_word in test_pairs:\n        src_tensor = tensor_from_word(src_word, src2idx)\n        trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n        output = model(src_tensor, trg_tensor, teacher_forcing_ratio=0.0)\n\n        # Character-level accuracy\n        pred_tokens = output.argmax(-1).view(-1)\n        true_tokens = trg_tensor.view(-1)\n        mask = true_tokens != trg2idx[\"<pad>\"]\n        correct = (pred_tokens == true_tokens) & mask\n        test_correct += correct.sum().item()\n        test_total += mask.sum().item()\n\n        # Word-level exact match via beam search\n        pred_str = beam_search(model, src_tensor, beam_size=beam_size)\n        if pred_str == trg_word:\n            exact_match_count += 1\n\ntest_char_acc = test_correct / test_total\ntest_exact_match = exact_match_count / len(test_pairs)\n\nprint(f\"Test Char Accuracy: {test_char_acc:.4f}\")\nprint(f\"Test Exact Match:  {test_exact_match:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T10:15:14.025806Z","iopub.execute_input":"2025-05-19T10:15:14.025974Z","iopub.status.idle":"2025-05-19T10:17:01.937083Z","shell.execute_reply.started":"2025-05-19T10:15:14.025959Z","shell.execute_reply":"2025-05-19T10:17:01.936395Z"}},"outputs":[{"name":"stdout","text":"Test Char Accuracy: 0.7523\nTest Exact Match:  0.3569\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"from tabulate import tabulate\n\ndef display_predictions(model, test_pairs, beam_size=3, max_samples=10):\n    model.eval()\n    table = []\n\n    with torch.no_grad():\n        sampled_pairs = random.sample(test_pairs, k=min(max_samples, len(test_pairs)))\n        for src_word, trg_word in sampled_pairs:\n            src_tensor = tensor_from_word(src_word, src2idx)\n            pred_str = beam_search(model, src_tensor, beam_size=beam_size)\n            match = \"✅\" if pred_str == trg_word else \"❌\"\n            table.append([src_word, pred_str, trg_word, match])\n\n    headers = [\"Input (Latin)\", \"Predicted (Telugu)\", \"Target (Telugu)\", \"Match\"]\n    print(tabulate(table, headers=headers, tablefmt=\"fancy_grid\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T10:17:01.937896Z","iopub.execute_input":"2025-05-19T10:17:01.938104Z","iopub.status.idle":"2025-05-19T10:17:01.966692Z","shell.execute_reply.started":"2025-05-19T10:17:01.938087Z","shell.execute_reply":"2025-05-19T10:17:01.965878Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"display_predictions(model, test_pairs, beam_size=best_config[\"beam_size\"], max_samples=30)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T10:17:01.967440Z","iopub.execute_input":"2025-05-19T10:17:01.967615Z","iopub.status.idle":"2025-05-19T10:17:02.437013Z","shell.execute_reply.started":"2025-05-19T10:17:01.967602Z","shell.execute_reply":"2025-05-19T10:17:02.436322Z"}},"outputs":[{"name":"stdout","text":"╒═══════════════════╤══════════════════════╤═══════════════════╤═════════╕\n│ Input (Latin)     │ Predicted (Telugu)   │ Target (Telugu)   │ Match   │\n╞═══════════════════╪══════════════════════╪═══════════════════╪═════════╡\n│ svasthalam        │ స్వస్థలం                │ స్వస్థలం             │ ✅      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ kalabandanu       │ కలబందను                │ కలబందను             │ ✅      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ jyootisha         │ జ్యోతీస                 │ జ్యోతిష              │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ suddhiga          │ సుద్దిగా                 │ శుద్ధిగా              │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ vaktalu           │ వక్తలు                 │ వక్తలు              │ ✅      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ prayaninchey      │ ప్రయణించేే                │ ప్రయాణించే             │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ neraaropanalu     │ నిరేరోకణలు               │ నేరారోపణలు            │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ avatharana        │ అవతార                 │ అవతరణ             │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ manomaya          │ మనోమయ                 │ మనోమయ              │ ✅      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ sophia            │ శోషియా                  │ సోఫియా               │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ narasimgaraavu    │ నరసింగరావు               │ నరసింగరావు            │ ✅      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ rogalu            │ రోగలు                  │ రోగాలు               │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ naayakudini       │ నాయకుడిని                │ నాయకుడిని             │ ✅      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ pramanamulu       │ ప్రమమణులు               │ ప్రమాణములు            │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ sikshanhatoe      │ సిక్షణతో                │ శిక్షణతో             │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ doopidiini        │ దూపిదీన                 │ దోపిడీని              │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ arcaa             │ ఆర్చా                  │ ఆర్కా               │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ mamdhamgaa        │ మంధంగా                  │ మందంగా               │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ varthamanam       │ వర్తణమం                │ వర్తమానం             │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ vahimchimdhi      │ వహించింది                 │ వహించింది              │ ✅      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ vyaktulanu        │ వ్యక్తులను               │ వ్యక్తులను            │ ✅      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ santvana          │ శంత్వాన                 │ సాంత్వన              │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ kover             │ కవర్                  │ కవర్               │ ✅      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ shastrachikitsalu │ శాష్ట్రిక్షరాలు             │ శస్త్రచికిత్సలు         │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ daariki           │ దారికి                  │ దారికి               │ ✅      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ chaineeyulu       │ చైనీయులు                 │ చైనీయులు              │ ✅      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ nibandhanalanu    │ నిబందనలు                │ నిబంధనలను            │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ waarrior          │ వారియర్                 │ వారియర్              │ ✅      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ telipe            │ తెలీప్                  │ తెలిపే               │ ❌      │\n├───────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ rakthaniki        │ రక్తణానికి               │ రక్తానికి             │ ❌      │\n╘═══════════════════╧══════════════════════╧═══════════════════╧═════════╛\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import csv, os, pandas as pd, torch\n\n# --- 1. Run model on the whole test set once ---\nmodel.eval()\nbeam = best_config[\"beam_size\"]\nrecords = []                         # rows for the output file\n\nwith torch.no_grad():\n    for latin, true in test_pairs:\n        pred = beam_search(model,\n                           tensor_from_word(latin, src2idx),\n                           beam_size=beam)\n        records.append({\"latin\": latin,\n                        \"true\": true,\n                        \"pred\": pred})\n\n# --- 2. Save as TSV (or CSV) ---\nout_df = pd.DataFrame(records)\nos.makedirs(\"predictions_vanilla\", exist_ok=True)          # local folder\nout_path = \"predictions_vanilla/test_predictions.tsv\"\nout_df.to_csv(out_path, sep=\"\\t\", index=False)\nprint(f\"Saved {len(out_df)} rows ➜ {out_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-19T10:17:02.437713Z","iopub.execute_input":"2025-05-19T10:17:02.437898Z","iopub.status.idle":"2025-05-19T10:18:25.327079Z","shell.execute_reply.started":"2025-05-19T10:17:02.437877Z","shell.execute_reply":"2025-05-19T10:18:25.326441Z"}},"outputs":[{"name":"stdout","text":"Saved 5747 rows ➜ predictions_vanilla/test_predictions.tsv\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}