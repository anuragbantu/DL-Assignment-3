{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11812889,"sourceType":"datasetVersion","datasetId":7419453}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:25:54.105391Z","iopub.execute_input":"2025-05-17T17:25:54.105735Z","iopub.status.idle":"2025-05-17T17:25:56.008079Z","shell.execute_reply.started":"2025-05-17T17:25:54.105693Z","shell.execute_reply":"2025-05-17T17:25:56.007323Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/telugu-lexicon/te.translit.sampled.train.tsv\n/kaggle/input/telugu-lexicon/te.translit.sampled.dev.tsv\n/kaggle/input/telugu-lexicon/te.translit.sampled.test.tsv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n# Load data\ntrain_df = pd.read_csv(\"/kaggle/input/telugu-lexicon/te.translit.sampled.train.tsv\", sep=\"\\t\", header=None)\ntrain_df.columns = [\"target\", \"source\", \"label\"]\n#pairs = list(zip(train_df[\"source\"], train_df[\"target\"]))  # Latin to Devanagari\n\n# Preview\n\nval_df = pd.read_csv(\"/kaggle/input/telugu-lexicon/te.translit.sampled.dev.tsv\", sep=\"\\t\", header=None)\nval_df.columns = [\"target\", \"source\", \"label\"]\n#val_pairs = list(zip(val_df[\"source\"], val_df[\"target\"]))\n\n# Drop any rows where source or target is missing\ntrain_df = train_df.dropna(subset=[\"source\", \"target\"])\nval_df = val_df.dropna(subset=[\"source\", \"target\"])\n\n# Ensure source and target are strings\ntrain_df[\"source\"] = train_df[\"source\"].astype(str)\ntrain_df[\"target\"] = train_df[\"target\"].astype(str)\nval_df[\"source\"] = val_df[\"source\"].astype(str)\nval_df[\"target\"] = val_df[\"target\"].astype(str)\n\n# Create pairs\npairs = list(zip(train_df[\"source\"], train_df[\"target\"]))\nval_pairs = list(zip(val_df[\"source\"], val_df[\"target\"]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:25:56.008790Z","iopub.execute_input":"2025-05-17T17:25:56.009075Z","iopub.status.idle":"2025-05-17T17:25:56.241319Z","shell.execute_reply.started":"2025-05-17T17:25:56.009057Z","shell.execute_reply":"2025-05-17T17:25:56.240683Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"print(len(val_pairs))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:25:56.242738Z","iopub.execute_input":"2025-05-17T17:25:56.243169Z","iopub.status.idle":"2025-05-17T17:25:56.248790Z","shell.execute_reply.started":"2025-05-17T17:25:56.243148Z","shell.execute_reply":"2025-05-17T17:25:56.246783Z"}},"outputs":[{"name":"stdout","text":"5683\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import random\n\nsample_size = 10000\npairs = random.sample(pairs, sample_size)    # use only 2000 training samples\n#val_pairs = random.sample(val_pairs, sample_size) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:25:56.249833Z","iopub.execute_input":"2025-05-17T17:25:56.250395Z","iopub.status.idle":"2025-05-17T17:25:56.275305Z","shell.execute_reply.started":"2025-05-17T17:25:56.250374Z","shell.execute_reply":"2025-05-17T17:25:56.273208Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:25:56.275803Z","iopub.execute_input":"2025-05-17T17:25:56.276019Z","iopub.status.idle":"2025-05-17T17:26:00.527303Z","shell.execute_reply.started":"2025-05-17T17:25:56.276001Z","shell.execute_reply":"2025-05-17T17:26:00.526770Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#pairs = list(zip(df[\"source\"], df[\"target\"]))\n\n#pairs = [\n #   (\"namaste\", \"नमस्ते\"),\n  #  (\"bharat\",  \"भारत\"),\n   # (\"duniya\",  \"दुनिया\"),\n    #(\"prem\",    \"प्रेम\"),\n#]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:26:00.527971Z","iopub.execute_input":"2025-05-17T17:26:00.528259Z","iopub.status.idle":"2025-05-17T17:26:00.531832Z","shell.execute_reply.started":"2025-05-17T17:26:00.528241Z","shell.execute_reply":"2025-05-17T17:26:00.531023Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"SRC_CHARS = set(\"\".join(s for s, _ in pairs))\nTRG_CHARS = set(\"\".join(t for _, t in pairs)) | {\"<sos>\", \"<eos>\"}\n\nsrc2idx = {ch: i+1 for i, ch in enumerate(sorted(SRC_CHARS))}  # reserve 0 for padding\nsrc2idx[\"<pad>\"] = 0\ntrg2idx = {ch: i+1 for i, ch in enumerate(sorted(TRG_CHARS))}\ntrg2idx[\"<pad>\"] = 0\n\nidx2trg = {i: ch for ch, i in trg2idx.items()}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:26:00.532673Z","iopub.execute_input":"2025-05-17T17:26:00.532961Z","iopub.status.idle":"2025-05-17T17:26:00.558116Z","shell.execute_reply.started":"2025-05-17T17:26:00.532934Z","shell.execute_reply":"2025-05-17T17:26:00.557495Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n# === RNN Cell Wrapper === #\ndef get_rnn_cell(cell_type):\n    cell_type = cell_type.upper()\n    if cell_type == \"GRU\":\n        return nn.GRU\n    elif cell_type == \"LSTM\":\n        return nn.LSTM\n    elif cell_type == \"RNN\":\n        return nn.RNN\n    else:\n        raise ValueError(\"Unsupported RNN cell type. Use 'RNN', 'GRU', or 'LSTM'.\")\n\n# === Encoder === #\nclass Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, hidden_dim, cell_type=\"GRU\", num_layers=1, dropout=0.0):\n        super().__init__()\n        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=0)\n        self.rnn = get_rnn_cell(cell_type)(\n            emb_dim, hidden_dim, num_layers, dropout=dropout if num_layers > 1 else 0.0\n        )\n    def forward(self, src):\n        embedded = self.embedding(src)  # [src_len, batch=1, emb_dim]\n        outputs, hidden = self.rnn(embedded)  # hidden: [num_layers, batch, hidden_dim]\n        return hidden\n\n# === Decoder === #\nclass Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, hidden_dim, cell_type=\"GRU\", num_layers=1, dropout=0.0):\n        super().__init__()\n        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=0)\n        self.rnn = get_rnn_cell(cell_type)(\n            emb_dim, hidden_dim, num_layers, dropout=dropout if num_layers > 1 else 0.0\n        )\n        self.out = nn.Linear(hidden_dim, output_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, input_step, hidden):\n        embedded = self.embedding(input_step)  # [1, 1, emb_dim]\n        output, hidden = self.rnn(embedded, hidden)\n        output = self.dropout(output.squeeze(0))  # Apply dropout to RNN output\n        prediction = self.out(output)             # [1, output_dim]\n        return prediction, hidden\n\n# === Seq2Seq Wrapper === #\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device, sos_idx):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n        self.sos_idx = sos_idx\n\n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        trg_len = trg.shape[0]\n        output_dim = self.decoder.out.out_features\n        outputs = torch.zeros(trg_len, 1, output_dim).to(self.device)\n\n        hidden = self.encoder(src)\n        hidden = self.adjust_hidden_for_decoder(hidden, self.decoder.rnn.num_layers)\n\n        input_step = torch.tensor([[self.sos_idx]], device=self.device)\n\n        for t in range(trg_len):\n            output, hidden = self.decoder(input_step, hidden)\n            outputs[t] = output\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = output.argmax(1).unsqueeze(0)\n            input_step = trg[t].unsqueeze(0) if teacher_force else top1\n\n        return outputs\n\n    def adjust_hidden_for_decoder(self, hidden, target_layers):\n        \"\"\"\n        Adjust the encoder's hidden state to match the number of decoder layers.\n        Pads if encoder has fewer layers, trims if more.\n        Works for GRU/RNN (tensor) and LSTM (tuple).\n        \"\"\"\n        if isinstance(hidden, tuple):  # LSTM\n            h, c = hidden\n            h = self._match_layers(h, target_layers)\n            c = self._match_layers(c, target_layers)\n            return (h, c)\n        else:  # GRU or RNN\n            return self._match_layers(hidden, target_layers)\n\n    def _match_layers(self, state, target_layers):\n        \"\"\"\n        Pad or trim the hidden state tensor to match target number of layers.\n        \"\"\"\n        current_layers = state.size(0)\n        if current_layers == target_layers:\n            return state\n        elif current_layers < target_layers:\n            diff = target_layers - current_layers\n            pad = torch.zeros(diff, state.size(1), state.size(2), device=state.device)\n            return torch.cat([state, pad], dim=0)\n        else:  # current_layers > target_layers\n            return state[:target_layers]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:26:00.559151Z","iopub.execute_input":"2025-05-17T17:26:00.559395Z","iopub.status.idle":"2025-05-17T17:26:00.573208Z","shell.execute_reply.started":"2025-05-17T17:26:00.559374Z","shell.execute_reply":"2025-05-17T17:26:00.572621Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"emb_dim = 64\nhidden_dim = 128\ncell_type = \"RNN\"  # or \"GRU\", \"RNN\"\nnum_layers = 2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:26:00.575632Z","iopub.execute_input":"2025-05-17T17:26:00.575917Z","iopub.status.idle":"2025-05-17T17:26:00.587233Z","shell.execute_reply.started":"2025-05-17T17:26:00.575896Z","shell.execute_reply":"2025-05-17T17:26:00.586600Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:26:00.587906Z","iopub.execute_input":"2025-05-17T17:26:00.588432Z","iopub.status.idle":"2025-05-17T17:26:00.673123Z","shell.execute_reply.started":"2025-05-17T17:26:00.588417Z","shell.execute_reply":"2025-05-17T17:26:00.672375Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"'''\nimport torch.optim as optim\n\nencoder = Encoder(len(src2idx), emb_dim, hidden_dim, cell_type, num_layers)\ndecoder = Decoder(len(trg2idx), emb_dim, hidden_dim, cell_type, num_layers)\nsos_idx = trg2idx[\"<sos>\"]\nmodel = Seq2Seq(encoder, decoder, DEVICE, sos_idx).to(DEVICE)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss(ignore_index=trg2idx[\"<pad>\"])\n'''\ndef tensor_from_word(word, mapping, add_eos=False):\n    indices = [mapping[ch] for ch in word]\n    if add_eos:\n        indices.append(mapping[\"<eos>\"])\n    return torch.tensor(indices, dtype=torch.long, device=DEVICE).unsqueeze(1)\n\n'''\nfor epoch in range(1, 6):\n    model.train()\n    epoch_loss = 0\n    train_correct = 0\n    train_total = 0\n\n    for src_word, trg_word in pairs:\n        src_tensor = tensor_from_word(src_word, src2idx)\n        trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n        optimizer.zero_grad()\n        output = model(src_tensor, trg_tensor)\n        output_dim = output.shape[-1]\n        loss = criterion(output.view(-1, output_dim), trg_tensor.view(-1))\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n\n        # Training accuracy\n        pred_tokens = output.argmax(-1).view(-1)\n        true_tokens = trg_tensor.view(-1)\n        mask = true_tokens != trg2idx[\"<pad>\"]\n        correct = (pred_tokens == true_tokens) & mask\n        train_correct += correct.sum().item()\n        train_total += mask.sum().item()\n\n    # Validation\n    model.eval()\n    val_loss = 0\n    val_correct = 0\n    val_total = 0\n    with torch.no_grad():\n        for src_word, trg_word in val_pairs:\n            src_tensor = tensor_from_word(src_word, src2idx)\n            trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n            output = model(src_tensor, trg_tensor)\n            loss = criterion(output.view(-1, output.shape[-1]), trg_tensor.view(-1))\n            val_loss += loss.item()\n\n            pred_tokens = output.argmax(-1).view(-1)\n            true_tokens = trg_tensor.view(-1)\n            mask = true_tokens != trg2idx[\"<pad>\"]\n            correct = (pred_tokens == true_tokens) & mask\n            val_correct += correct.sum().item()\n            val_total += mask.sum().item()\n\n    train_acc = train_correct / train_total\n    val_acc = val_correct / val_total\n    print(f\"Epoch {epoch:3d} | Train Loss: {epoch_loss/len(pairs):.4f} | \"\n          f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_pairs):.4f} | Val Acc: {val_acc:.4f}\")\n\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:26:00.674140Z","iopub.execute_input":"2025-05-17T17:26:00.674407Z","iopub.status.idle":"2025-05-17T17:26:00.690567Z","shell.execute_reply.started":"2025-05-17T17:26:00.674373Z","shell.execute_reply":"2025-05-17T17:26:00.689812Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'\\nfor epoch in range(1, 6):\\n    model.train()\\n    epoch_loss = 0\\n    train_correct = 0\\n    train_total = 0\\n\\n    for src_word, trg_word in pairs:\\n        src_tensor = tensor_from_word(src_word, src2idx)\\n        trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\\n\\n        optimizer.zero_grad()\\n        output = model(src_tensor, trg_tensor)\\n        output_dim = output.shape[-1]\\n        loss = criterion(output.view(-1, output_dim), trg_tensor.view(-1))\\n        loss.backward()\\n        optimizer.step()\\n        epoch_loss += loss.item()\\n\\n        # Training accuracy\\n        pred_tokens = output.argmax(-1).view(-1)\\n        true_tokens = trg_tensor.view(-1)\\n        mask = true_tokens != trg2idx[\"<pad>\"]\\n        correct = (pred_tokens == true_tokens) & mask\\n        train_correct += correct.sum().item()\\n        train_total += mask.sum().item()\\n\\n    # Validation\\n    model.eval()\\n    val_loss = 0\\n    val_correct = 0\\n    val_total = 0\\n    with torch.no_grad():\\n        for src_word, trg_word in val_pairs:\\n            src_tensor = tensor_from_word(src_word, src2idx)\\n            trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\\n            output = model(src_tensor, trg_tensor)\\n            loss = criterion(output.view(-1, output.shape[-1]), trg_tensor.view(-1))\\n            val_loss += loss.item()\\n\\n            pred_tokens = output.argmax(-1).view(-1)\\n            true_tokens = trg_tensor.view(-1)\\n            mask = true_tokens != trg2idx[\"<pad>\"]\\n            correct = (pred_tokens == true_tokens) & mask\\n            val_correct += correct.sum().item()\\n            val_total += mask.sum().item()\\n\\n    train_acc = train_correct / train_total\\n    val_acc = val_correct / val_total\\n    print(f\"Epoch {epoch:3d} | Train Loss: {epoch_loss/len(pairs):.4f} | \"\\n          f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_pairs):.4f} | Val Acc: {val_acc:.4f}\")\\n\\n'"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"def beam_search(model, src_tensor, beam_size=3, max_len=30):\n    model.eval()\n    with torch.no_grad():\n        hidden = model.encoder(src_tensor)\n        hidden = model.adjust_hidden_for_decoder(hidden, model.decoder.rnn.num_layers)\n\n\n        if isinstance(hidden, tuple):\n            h, c = hidden\n            hidden = (\n                h[:model.decoder.rnn.num_layers],\n                c[:model.decoder.rnn.num_layers],\n            )\n        else:\n            hidden = hidden[:model.decoder.rnn.num_layers]\n\n        sequences = [([model.sos_idx], 0.0, hidden)]\n\n        for _ in range(max_len):\n            all_candidates = []\n            for seq, score, h in sequences:\n                input_step = torch.tensor([[seq[-1]]], device=model.device)\n                output, h_new = model.decoder(input_step, h)\n                probs = torch.log_softmax(output, dim=1)\n                topk = torch.topk(probs, beam_size)\n\n                for i in range(beam_size):\n                    token = topk.indices[0][i].item()\n                    token_score = topk.values[0][i].item()\n                    new_seq = seq + [token]\n                    all_candidates.append((new_seq, score + token_score, h_new))\n\n            sequences = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_size]\n\n            if all(seq[-1] == trg2idx[\"<eos>\"] for seq, _, _ in sequences):\n                break\n\n        best_seq = sequences[0][0][1:]  # remove <sos>\n        return \"\".join([idx2trg[i] for i in best_seq if i != trg2idx[\"<eos>\"]])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:26:00.691651Z","iopub.execute_input":"2025-05-17T17:26:00.691938Z","iopub.status.idle":"2025-05-17T17:26:00.704591Z","shell.execute_reply.started":"2025-05-17T17:26:00.691914Z","shell.execute_reply":"2025-05-17T17:26:00.703910Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"!pip install -q wandb\nimport wandb\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:26:00.705282Z","iopub.execute_input":"2025-05-17T17:26:00.705491Z","iopub.status.idle":"2025-05-17T17:26:07.370543Z","shell.execute_reply.started":"2025-05-17T17:26:00.705475Z","shell.execute_reply":"2025-05-17T17:26:07.369939Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"wandb.login(key='af7d7cf29d8954a13afb06c7a0d0c196c36ac51b')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:26:07.371423Z","iopub.execute_input":"2025-05-17T17:26:07.371851Z","iopub.status.idle":"2025-05-17T17:26:13.416506Z","shell.execute_reply.started":"2025-05-17T17:26:07.371831Z","shell.execute_reply":"2025-05-17T17:26:13.415782Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma24m003\u001b[0m (\u001b[33mma24m003-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"sweep_config = {\n    \"method\": \"bayes\",\n    \"metric\": {\"name\": \"val_acc\", \"goal\": \"maximize\"},\n    \"parameters\": {\n        \"emb_dim\": {\"values\": [16,32,64,256]},\n        \"hidden_dim\": {\"values\": [16,32,64,256]},\n        \"cell_type\": {\"values\": [\"RNN\",\"GRU\",\"LSTM\"]},\n        \"enc_layers\": {\"values\": [1,2,3]},\n        \"dec_layers\": {\"values\": [1, 2, 3]},\n        \"dropout\": {\"values\": [0,0.2, 0.3]},\n        \"beam_size\": {\"values\": [1, 3, 2]},\n        \"lr\": {\"values\": [0.001, 0.0005]},\n        \"teacher_forcing_ratio\": {\"values\": [0.3, 0.5, 0.7, 1.0]}\n\n    }\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:26:13.417306Z","iopub.execute_input":"2025-05-17T17:26:13.417678Z","iopub.status.idle":"2025-05-17T17:26:13.422542Z","shell.execute_reply.started":"2025-05-17T17:26:13.417661Z","shell.execute_reply":"2025-05-17T17:26:13.421899Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def train_model(config=None):\n    with wandb.init(config=config) as run:\n        config = wandb.config\n\n        run.name = f\"emb{config.emb_dim}_hid{config.hidden_dim}_{config.cell_type}_enc{config.enc_layers}_dec{config.dec_layers}_drop{int(config.dropout*100)}_beam{config.beam_size}_lr{config.lr}\"\n\n        encoder = Encoder(len(src2idx), config.emb_dim, config.hidden_dim,\n                          config.cell_type, config.enc_layers, config.dropout)\n        decoder = Decoder(len(trg2idx), config.emb_dim, config.hidden_dim,\n                          config.cell_type, config.dec_layers, config.dropout)\n        model = Seq2Seq(encoder, decoder, DEVICE, sos_idx=trg2idx[\"<sos>\"]).to(DEVICE)\n\n        optimizer = optim.Adam(model.parameters(), lr=config.lr)\n        criterion = nn.CrossEntropyLoss(ignore_index=trg2idx[\"<pad>\"])\n        beam_size = config.get(\"beam_size\", 3)\n\n        for epoch in range(1, 6):\n            model.train()\n            total_loss = 0\n            train_correct = 0\n            train_total = 0\n\n            for src_word, trg_word in pairs:\n                src_tensor = tensor_from_word(src_word, src2idx)\n                trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n                optimizer.zero_grad()\n                output = model(src_tensor, trg_tensor, teacher_forcing_ratio=config.get(\"teacher_forcing_ratio\", 0.5))\n                loss = criterion(output.view(-1, output.size(-1)), trg_tensor.view(-1))\n                loss.backward()\n                optimizer.step()\n                total_loss += loss.item()\n\n                pred_tokens = output.argmax(-1).view(-1)\n                true_tokens = trg_tensor.view(-1)\n                mask = true_tokens != trg2idx[\"<pad>\"]\n                correct = (pred_tokens == true_tokens) & mask\n                train_correct += correct.sum().item()\n                train_total += mask.sum().item()\n\n            model.eval()\n            val_loss = 0\n            val_correct = 0\n            val_total = 0\n            exact_match_count = 0\n\n            with torch.no_grad():\n                for src_word, trg_word in val_pairs:\n                    src_tensor = tensor_from_word(src_word, src2idx)\n                    trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n                    output = model(src_tensor, trg_tensor, teacher_forcing_ratio=0.0)\n                    loss = criterion(output.view(-1, output.size(-1)), trg_tensor.view(-1))\n                    val_loss += loss.item()\n\n                    pred_tokens = output.argmax(-1).view(-1)\n                    true_tokens = trg_tensor.view(-1)\n                    mask = true_tokens != trg2idx[\"<pad>\"]\n                    correct = (pred_tokens == true_tokens) & mask\n                    val_correct += correct.sum().item()\n                    val_total += mask.sum().item()\n\n                    # Beam search for exact match accuracy\n                    pred_str = beam_search(model, src_tensor, beam_size=beam_size)\n                    if pred_str == trg_word:\n                        exact_match_count += 1\n\n            train_acc = train_correct / train_total\n            val_acc = val_correct / val_total\n            exact_match = exact_match_count / len(val_pairs)\n            \n            print(f\"Epoch {epoch:2d} | \"\n                  f\"Train Loss: {total_loss / len(pairs):.4f} | \"\n                  f\"Train Acc: {train_acc:.4f} | \"\n                  f\"Val Loss: {val_loss / len(val_pairs):.4f} | \"\n                  f\"Val Acc: {val_acc:.4f} | \"\n                  f\"Val Exact Match: {exact_match:.4f} | \"\n                  f\"Beam Size: {beam_size}\")\n\n            \n            wandb.log({\n                \"epoch\": epoch,\n                \"train_loss\": total_loss / len(pairs),\n                \"val_loss\": val_loss / len(val_pairs),\n                \"train_accuracy\": train_correct / train_total,\n                \"val_accuracy\": val_correct / val_total,\n                \"val_exact_match\": exact_match_count / len(val_pairs),\n                \"beam_size\": beam_size\n            })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:26:13.423230Z","iopub.execute_input":"2025-05-17T17:26:13.423404Z","iopub.status.idle":"2025-05-17T17:26:13.445384Z","shell.execute_reply.started":"2025-05-17T17:26:13.423390Z","shell.execute_reply":"2025-05-17T17:26:13.444810Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"'''\nsweep_id = wandb.sweep(sweep_config, project=\"transliteration-sweep\")\nwandb.agent(sweep_id, function=train_model, count=100)\nwandb.finish()\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:26:13.446084Z","iopub.execute_input":"2025-05-17T17:26:13.446308Z","iopub.status.idle":"2025-05-17T17:26:13.461571Z","shell.execute_reply.started":"2025-05-17T17:26:13.446289Z","shell.execute_reply":"2025-05-17T17:26:13.460985Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"'\\nsweep_id = wandb.sweep(sweep_config, project=\"transliteration-sweep\")\\nwandb.agent(sweep_id, function=train_model, count=100)\\nwandb.finish()\\n'"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"best_config = {\n    \"emb_dim\": 32,\n    \"hidden_dim\": 256,\n    \"cell_type\": \"LSTM\",\n    \"enc_layers\": 3,\n    \"dec_layers\": 2,\n    \"dropout\": 0,\n    \"beam_size\": 3,\n    \"lr\": 0.001}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:26:13.462184Z","iopub.execute_input":"2025-05-17T17:26:13.462379Z","iopub.status.idle":"2025-05-17T17:26:13.475188Z","shell.execute_reply.started":"2025-05-17T17:26:13.462365Z","shell.execute_reply":"2025-05-17T17:26:13.474613Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def best_train_model(config=None):\n    with wandb.init(config=config):\n        config = wandb.config\n\n        encoder = Encoder(len(src2idx), config.emb_dim, config.hidden_dim,\n                          config.cell_type, config.enc_layers, config.dropout)\n        decoder = Decoder(len(trg2idx), config.emb_dim, config.hidden_dim,\n                          config.cell_type, config.dec_layers, config.dropout)\n        model = Seq2Seq(encoder, decoder, DEVICE, sos_idx=trg2idx[\"<sos>\"]).to(DEVICE)\n\n        optimizer = optim.Adam(model.parameters(), lr=config.lr)\n        criterion = nn.CrossEntropyLoss(ignore_index=trg2idx[\"<pad>\"])\n        beam_size = config.get(\"beam_size\", 3)\n\n        for epoch in range(1, 10):\n            model.train()\n            total_loss = 0\n            train_correct = 0\n            train_total = 0\n\n            for src_word, trg_word in pairs:\n                src_tensor = tensor_from_word(src_word, src2idx)\n                trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n                optimizer.zero_grad()\n                output = model(src_tensor, trg_tensor, teacher_forcing_ratio=config.get(\"teacher_forcing_ratio\", 0.5))\n                loss = criterion(output.view(-1, output.size(-1)), trg_tensor.view(-1))\n                loss.backward()\n                optimizer.step()\n                total_loss += loss.item()\n\n                pred_tokens = output.argmax(-1).view(-1)\n                true_tokens = trg_tensor.view(-1)\n                mask = true_tokens != trg2idx[\"<pad>\"]\n                correct = (pred_tokens == true_tokens) & mask\n                train_correct += correct.sum().item()\n                train_total += mask.sum().item()\n\n            model.eval()\n            val_loss = 0\n            val_correct = 0\n            val_total = 0\n            exact_match_count = 0\n\n            with torch.no_grad():\n                for src_word, trg_word in val_pairs:\n                    src_tensor = tensor_from_word(src_word, src2idx)\n                    trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n                    output = model(src_tensor, trg_tensor, teacher_forcing_ratio=0.0)\n                    loss = criterion(output.view(-1, output.size(-1)), trg_tensor.view(-1))\n                    val_loss += loss.item()\n\n                    pred_tokens = output.argmax(-1).view(-1)\n                    true_tokens = trg_tensor.view(-1)\n                    mask = true_tokens != trg2idx[\"<pad>\"]\n                    correct = (pred_tokens == true_tokens) & mask\n                    val_correct += correct.sum().item()\n                    val_total += mask.sum().item()\n\n                    # Beam search for exact match accuracy\n                    pred_str = beam_search(model, src_tensor, beam_size=beam_size)\n                    if pred_str == trg_word:\n                        exact_match_count += 1\n\n            train_acc = train_correct / train_total\n            val_acc = val_correct / val_total\n            exact_match = exact_match_count / len(val_pairs)\n\n            print(f\"Epoch {epoch:2d} | \"\n                  f\"Train Loss: {total_loss / len(pairs):.4f} | \"\n                  f\"Train Acc: {train_acc:.4f} | \"\n                  f\"Val Loss: {val_loss / len(val_pairs):.4f} | \"\n                  f\"Val Acc: {val_acc:.4f} | \"\n                  f\"Val Exact Match: {exact_match:.4f} | \"\n                  f\"Beam Size: {beam_size}\")\n\n            wandb.log({\n                \"epoch\": epoch,\n                \"train_loss\": total_loss / len(pairs),\n                \"val_loss\": val_loss / len(val_pairs),\n                \"train_accuracy\": train_acc,\n                \"val_accuracy\": val_acc,\n                \"val_exact_match\": exact_match,\n                \"beam_size\": beam_size\n            })\n\n        return model  \n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:26:13.475833Z","iopub.execute_input":"2025-05-17T17:26:13.476077Z","iopub.status.idle":"2025-05-17T17:26:13.488347Z","shell.execute_reply.started":"2025-05-17T17:26:13.476054Z","shell.execute_reply":"2025-05-17T17:26:13.487785Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"model = best_train_model(config=best_config)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T17:26:13.489009Z","iopub.execute_input":"2025-05-17T17:26:13.489232Z","iopub.status.idle":"2025-05-17T18:10:03.046751Z","shell.execute_reply.started":"2025-05-17T17:26:13.489210Z","shell.execute_reply":"2025-05-17T18:10:03.046226Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250517_172613-yg55r0a5</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma24m003-iit-madras/uncategorized/runs/yg55r0a5' target=\"_blank\">visionary-yogurt-30</a></strong> to <a href='https://wandb.ai/ma24m003-iit-madras/uncategorized' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma24m003-iit-madras/uncategorized' target=\"_blank\">https://wandb.ai/ma24m003-iit-madras/uncategorized</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma24m003-iit-madras/uncategorized/runs/yg55r0a5' target=\"_blank\">https://wandb.ai/ma24m003-iit-madras/uncategorized/runs/yg55r0a5</a>"},"metadata":{}},{"name":"stdout","text":"Epoch  1 | Train Loss: 1.8568 | Train Acc: 0.4796 | Val Loss: 1.3234 | Val Acc: 0.6003 | Val Exact Match: 0.1258 | Beam Size: 3\nEpoch  2 | Train Loss: 0.7910 | Train Acc: 0.7616 | Val Loss: 1.0493 | Val Acc: 0.6928 | Val Exact Match: 0.1941 | Beam Size: 3\nEpoch  3 | Train Loss: 0.5265 | Train Acc: 0.8390 | Val Loss: 1.0341 | Val Acc: 0.7188 | Val Exact Match: 0.2618 | Beam Size: 3\nEpoch  4 | Train Loss: 0.3847 | Train Acc: 0.8822 | Val Loss: 1.0757 | Val Acc: 0.7310 | Val Exact Match: 0.3030 | Beam Size: 3\nEpoch  5 | Train Loss: 0.2949 | Train Acc: 0.9099 | Val Loss: 1.1332 | Val Acc: 0.7359 | Val Exact Match: 0.2756 | Beam Size: 3\nEpoch  6 | Train Loss: 0.2452 | Train Acc: 0.9254 | Val Loss: 1.1698 | Val Acc: 0.7464 | Val Exact Match: 0.3195 | Beam Size: 3\nEpoch  7 | Train Loss: 0.2098 | Train Acc: 0.9348 | Val Loss: 1.1734 | Val Acc: 0.7433 | Val Exact Match: 0.3250 | Beam Size: 3\nEpoch  8 | Train Loss: 0.1874 | Train Acc: 0.9417 | Val Loss: 1.1979 | Val Acc: 0.7461 | Val Exact Match: 0.3069 | Beam Size: 3\nEpoch  9 | Train Loss: 0.1674 | Train Acc: 0.9479 | Val Loss: 1.3005 | Val Acc: 0.7445 | Val Exact Match: 0.3516 | Beam Size: 3\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>beam_size</td><td>▁▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▂▃▄▅▅▆▇█</td></tr><tr><td>train_accuracy</td><td>▁▅▆▇▇████</td></tr><tr><td>train_loss</td><td>█▄▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▇▇▇████</td></tr><tr><td>val_exact_match</td><td>▁▃▅▆▆▇▇▇█</td></tr><tr><td>val_loss</td><td>█▁▁▂▃▄▄▅▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>beam_size</td><td>3</td></tr><tr><td>epoch</td><td>9</td></tr><tr><td>train_accuracy</td><td>0.9479</td></tr><tr><td>train_loss</td><td>0.16738</td></tr><tr><td>val_accuracy</td><td>0.74454</td></tr><tr><td>val_exact_match</td><td>0.35157</td></tr><tr><td>val_loss</td><td>1.30046</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">visionary-yogurt-30</strong> at: <a href='https://wandb.ai/ma24m003-iit-madras/uncategorized/runs/yg55r0a5' target=\"_blank\">https://wandb.ai/ma24m003-iit-madras/uncategorized/runs/yg55r0a5</a><br> View project at: <a href='https://wandb.ai/ma24m003-iit-madras/uncategorized' target=\"_blank\">https://wandb.ai/ma24m003-iit-madras/uncategorized</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250517_172613-yg55r0a5/logs</code>"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"\ntest_df = pd.read_csv(\"/kaggle/input/telugu-lexicon/te.translit.sampled.test.tsv\", sep=\"\\t\", header=None)\ntest_df.columns = [\"target\", \"source\", \"label\"]  # adjust if only 2 columns\ntest_df = test_df.dropna(subset=[\"source\", \"target\"])\ntest_df[\"source\"] = test_df[\"source\"].astype(str)\ntest_df[\"target\"] = test_df[\"target\"].astype(str)\ntest_pairs = list(zip(test_df[\"source\"], test_df[\"target\"]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T18:10:03.047630Z","iopub.execute_input":"2025-05-17T18:10:03.048182Z","iopub.status.idle":"2025-05-17T18:10:03.093785Z","shell.execute_reply.started":"2025-05-17T18:10:03.048164Z","shell.execute_reply":"2025-05-17T18:10:03.093301Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"print(len(test_pairs))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T18:10:03.094534Z","iopub.execute_input":"2025-05-17T18:10:03.094795Z","iopub.status.idle":"2025-05-17T18:10:03.098520Z","shell.execute_reply.started":"2025-05-17T18:10:03.094772Z","shell.execute_reply":"2025-05-17T18:10:03.097774Z"}},"outputs":[{"name":"stdout","text":"5747\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"model.eval()\ntest_correct = 0\ntest_total = 0\nexact_match_count = 0\nbeam_size = best_config[\"beam_size\"]\n\nwith torch.no_grad():\n    for src_word, trg_word in test_pairs:\n        src_tensor = tensor_from_word(src_word, src2idx)\n        trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n        output = model(src_tensor, trg_tensor, teacher_forcing_ratio=0.0)\n\n        # Character-level accuracy\n        pred_tokens = output.argmax(-1).view(-1)\n        true_tokens = trg_tensor.view(-1)\n        mask = true_tokens != trg2idx[\"<pad>\"]\n        correct = (pred_tokens == true_tokens) & mask\n        test_correct += correct.sum().item()\n        test_total += mask.sum().item()\n\n        # Word-level exact match via beam search\n        pred_str = beam_search(model, src_tensor, beam_size=beam_size)\n        if pred_str == trg_word:\n            exact_match_count += 1\n\ntest_char_acc = test_correct / test_total\ntest_exact_match = exact_match_count / len(test_pairs)\n\nprint(f\"Test Char Accuracy: {test_char_acc:.4f}\")\nprint(f\"Test Exact Match:  {test_exact_match:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T18:10:03.099375Z","iopub.execute_input":"2025-05-17T18:10:03.099819Z","iopub.status.idle":"2025-05-17T18:11:51.772844Z","shell.execute_reply.started":"2025-05-17T18:10:03.099803Z","shell.execute_reply":"2025-05-17T18:11:51.772212Z"}},"outputs":[{"name":"stdout","text":"Test Char Accuracy: 0.7460\nTest Exact Match:  0.3518\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"from tabulate import tabulate\n\ndef display_predictions(model, test_pairs, beam_size=3, max_samples=10):\n    model.eval()\n    table = []\n\n    with torch.no_grad():\n        sampled_pairs = random.sample(test_pairs, k=min(max_samples, len(test_pairs)))\n        for src_word, trg_word in sampled_pairs:\n            src_tensor = tensor_from_word(src_word, src2idx)\n            pred_str = beam_search(model, src_tensor, beam_size=beam_size)\n            match = \"✅\" if pred_str == trg_word else \"❌\"\n            table.append([src_word, pred_str, trg_word, match])\n\n    headers = [\"Input (Latin)\", \"Predicted (Telugu)\", \"Target (Telugu)\", \"Match\"]\n    print(tabulate(table, headers=headers, tablefmt=\"fancy_grid\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T18:11:51.773601Z","iopub.execute_input":"2025-05-17T18:11:51.773847Z","iopub.status.idle":"2025-05-17T18:11:51.801343Z","shell.execute_reply.started":"2025-05-17T18:11:51.773830Z","shell.execute_reply":"2025-05-17T18:11:51.800895Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"display_predictions(model, test_pairs, beam_size=best_config[\"beam_size\"], max_samples=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-17T18:13:03.095178Z","iopub.execute_input":"2025-05-17T18:13:03.095822Z","iopub.status.idle":"2025-05-17T18:13:03.239615Z","shell.execute_reply.started":"2025-05-17T18:13:03.095803Z","shell.execute_reply":"2025-05-17T18:13:03.238980Z"}},"outputs":[{"name":"stdout","text":"╒═════════════════╤══════════════════════╤═══════════════════╤═════════╕\n│ Input (Latin)   │ Predicted (Telugu)   │ Target (Telugu)   │ Match   │\n╞═════════════════╪══════════════════════╪═══════════════════╪═════════╡\n│ bible           │ బిబీలు                  │ బైబిల్               │ ❌      │\n├─────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ kuuragaayalanu  │ కూరాగయాలను               │ కూరగాయలను            │ ❌      │\n├─────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ agency          │ అజెన్నీ                 │ ఏజన్సీ              │ ❌      │\n├─────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ dhaampatya      │ దాంపత్య                 │ దాంపత్య              │ ✅      │\n├─────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ prasaaraala     │ ప్రసారాల                │ ప్రసారాల             │ ✅      │\n├─────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ satyaalu        │ సత్యాలు                 │ సత్యాలు              │ ✅      │\n├─────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ prudhu          │ పృదు                   │ పృథు                │ ❌      │\n├─────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ pradhaanamiena  │ ప్రధానమైన               │ ప్రధానమైన            │ ✅      │\n├─────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ dhashaabdhaalu  │ దశాబ్దాలు                │ దశాబ్దాలు             │ ✅      │\n├─────────────────┼──────────────────────┼───────────────────┼─────────┤\n│ keerti          │ కేర్తి                  │ కీర్తి               │ ❌      │\n╘═════════════════╧══════════════════════╧═══════════════════╧═════════╛\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}