{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11812889,"sourceType":"datasetVersion","datasetId":7419453}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:06.397724Z","iopub.execute_input":"2025-05-16T11:39:06.397955Z","iopub.status.idle":"2025-05-16T11:39:06.713384Z","shell.execute_reply.started":"2025-05-16T11:39:06.397935Z","shell.execute_reply":"2025-05-16T11:39:06.712508Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/telugu-lexicon/te.translit.sampled.train.tsv\n/kaggle/input/telugu-lexicon/te.translit.sampled.dev.tsv\n/kaggle/input/telugu-lexicon/te.translit.sampled.test.tsv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\n\n# Load data\ntrain_df = pd.read_csv(\"/kaggle/input/telugu-lexicon/te.translit.sampled.train.tsv\", sep=\"\\t\", header=None)\ntrain_df.columns = [\"target\", \"source\", \"label\"]\n#pairs = list(zip(train_df[\"source\"], train_df[\"target\"]))  # Latin to Devanagari\n\n# Preview\n\nval_df = pd.read_csv(\"/kaggle/input/telugu-lexicon/te.translit.sampled.dev.tsv\", sep=\"\\t\", header=None)\nval_df.columns = [\"target\", \"source\", \"label\"]\n#val_pairs = list(zip(val_df[\"source\"], val_df[\"target\"]))\n\n# Drop any rows where source or target is missing\ntrain_df = train_df.dropna(subset=[\"source\", \"target\"])\nval_df = val_df.dropna(subset=[\"source\", \"target\"])\n\n# Ensure source and target are strings\ntrain_df[\"source\"] = train_df[\"source\"].astype(str)\ntrain_df[\"target\"] = train_df[\"target\"].astype(str)\nval_df[\"source\"] = val_df[\"source\"].astype(str)\nval_df[\"target\"] = val_df[\"target\"].astype(str)\n\n# Create pairs\npairs = list(zip(train_df[\"source\"], train_df[\"target\"]))\nval_pairs = list(zip(val_df[\"source\"], val_df[\"target\"]))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:06.714323Z","iopub.execute_input":"2025-05-16T11:39:06.714756Z","iopub.status.idle":"2025-05-16T11:39:06.955460Z","shell.execute_reply.started":"2025-05-16T11:39:06.714715Z","shell.execute_reply":"2025-05-16T11:39:06.954589Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"print(len(val_pairs))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:06.957597Z","iopub.execute_input":"2025-05-16T11:39:06.957867Z","iopub.status.idle":"2025-05-16T11:39:06.962465Z","shell.execute_reply.started":"2025-05-16T11:39:06.957847Z","shell.execute_reply":"2025-05-16T11:39:06.961373Z"}},"outputs":[{"name":"stdout","text":"5683\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import random\n\nsample_size = 10000\npairs = random.sample(pairs, sample_size)    # use only 2000 training samples\n#val_pairs = random.sample(val_pairs, sample_size) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:06.963382Z","iopub.execute_input":"2025-05-16T11:39:06.963662Z","iopub.status.idle":"2025-05-16T11:39:06.985134Z","shell.execute_reply.started":"2025-05-16T11:39:06.963636Z","shell.execute_reply":"2025-05-16T11:39:06.984153Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:06.985977Z","iopub.execute_input":"2025-05-16T11:39:06.986312Z","iopub.status.idle":"2025-05-16T11:39:11.296398Z","shell.execute_reply.started":"2025-05-16T11:39:06.986286Z","shell.execute_reply":"2025-05-16T11:39:11.295483Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"#pairs = list(zip(df[\"source\"], df[\"target\"]))\n\n#pairs = [\n #   (\"namaste\", \"नमस्ते\"),\n  #  (\"bharat\",  \"भारत\"),\n   # (\"duniya\",  \"दुनिया\"),\n    #(\"prem\",    \"प्रेम\"),\n#]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:11.297304Z","iopub.execute_input":"2025-05-16T11:39:11.297767Z","iopub.status.idle":"2025-05-16T11:39:11.301755Z","shell.execute_reply.started":"2025-05-16T11:39:11.297723Z","shell.execute_reply":"2025-05-16T11:39:11.300971Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"SRC_CHARS = set(\"\".join(s for s, _ in pairs))\nTRG_CHARS = set(\"\".join(t for _, t in pairs)) | {\"<sos>\", \"<eos>\"}\n\nsrc2idx = {ch: i+1 for i, ch in enumerate(sorted(SRC_CHARS))}  # reserve 0 for padding\nsrc2idx[\"<pad>\"] = 0\ntrg2idx = {ch: i+1 for i, ch in enumerate(sorted(TRG_CHARS))}\ntrg2idx[\"<pad>\"] = 0\n\nidx2trg = {i: ch for ch, i in trg2idx.items()}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:11.302517Z","iopub.execute_input":"2025-05-16T11:39:11.302726Z","iopub.status.idle":"2025-05-16T11:39:11.337047Z","shell.execute_reply.started":"2025-05-16T11:39:11.302704Z","shell.execute_reply":"2025-05-16T11:39:11.336238Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\n# === RNN Cell Wrapper === #\ndef get_rnn_cell(cell_type):\n    cell_type = cell_type.upper()\n    if cell_type == \"GRU\":\n        return nn.GRU\n    elif cell_type == \"LSTM\":\n        return nn.LSTM\n    elif cell_type == \"RNN\":\n        return nn.RNN\n    else:\n        raise ValueError(\"Unsupported RNN cell type. Use 'RNN', 'GRU', or 'LSTM'.\")\n\n# === Encoder === #\nclass Encoder(nn.Module):\n    def __init__(self, input_dim, emb_dim, hidden_dim, cell_type=\"GRU\", num_layers=1, dropout=0.0):\n        super().__init__()\n        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx=0)\n        self.rnn = get_rnn_cell(cell_type)(\n            emb_dim, hidden_dim, num_layers, dropout=dropout if num_layers > 1 else 0.0\n        )\n    def forward(self, src):\n        embedded = self.embedding(src)  # [src_len, batch=1, emb_dim]\n        outputs, hidden = self.rnn(embedded)  # hidden: [num_layers, batch, hidden_dim]\n        return hidden\n\n# === Decoder === #\nclass Decoder(nn.Module):\n    def __init__(self, output_dim, emb_dim, hidden_dim, cell_type=\"GRU\", num_layers=1, dropout=0.0):\n        super().__init__()\n        self.embedding = nn.Embedding(output_dim, emb_dim, padding_idx=0)\n        self.rnn = get_rnn_cell(cell_type)(\n            emb_dim, hidden_dim, num_layers, dropout=dropout if num_layers > 1 else 0.0\n        )\n        self.out = nn.Linear(hidden_dim, output_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, input_step, hidden):\n        embedded = self.embedding(input_step)  # [1, 1, emb_dim]\n        output, hidden = self.rnn(embedded, hidden)\n        output = self.dropout(output.squeeze(0))  # Apply dropout to RNN output\n        prediction = self.out(output)             # [1, output_dim]\n        return prediction, hidden\n\n# === Seq2Seq Wrapper === #\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder, device, sos_idx):\n        super().__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        self.device = device\n        self.sos_idx = sos_idx\n\n    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n        trg_len = trg.shape[0]\n        output_dim = self.decoder.out.out_features\n        outputs = torch.zeros(trg_len, 1, output_dim).to(self.device)\n\n        hidden = self.encoder(src)\n        hidden = self.adjust_hidden_for_decoder(hidden, self.decoder.rnn.num_layers)\n\n        input_step = torch.tensor([[self.sos_idx]], device=self.device)\n\n        for t in range(trg_len):\n            output, hidden = self.decoder(input_step, hidden)\n            outputs[t] = output\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = output.argmax(1).unsqueeze(0)\n            input_step = trg[t].unsqueeze(0) if teacher_force else top1\n\n        return outputs\n\n    def adjust_hidden_for_decoder(self, hidden, target_layers):\n        \"\"\"\n        Adjust the encoder's hidden state to match the number of decoder layers.\n        Pads if encoder has fewer layers, trims if more.\n        Works for GRU/RNN (tensor) and LSTM (tuple).\n        \"\"\"\n        if isinstance(hidden, tuple):  # LSTM\n            h, c = hidden\n            h = self._match_layers(h, target_layers)\n            c = self._match_layers(c, target_layers)\n            return (h, c)\n        else:  # GRU or RNN\n            return self._match_layers(hidden, target_layers)\n\n    def _match_layers(self, state, target_layers):\n        \"\"\"\n        Pad or trim the hidden state tensor to match target number of layers.\n        \"\"\"\n        current_layers = state.size(0)\n        if current_layers == target_layers:\n            return state\n        elif current_layers < target_layers:\n            diff = target_layers - current_layers\n            pad = torch.zeros(diff, state.size(1), state.size(2), device=state.device)\n            return torch.cat([state, pad], dim=0)\n        else:  # current_layers > target_layers\n            return state[:target_layers]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:11.337944Z","iopub.execute_input":"2025-05-16T11:39:11.338324Z","iopub.status.idle":"2025-05-16T11:39:11.355740Z","shell.execute_reply.started":"2025-05-16T11:39:11.338303Z","shell.execute_reply":"2025-05-16T11:39:11.355048Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"emb_dim = 64\nhidden_dim = 128\ncell_type = \"RNN\"  # or \"GRU\", \"RNN\"\nnum_layers = 2\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:11.358485Z","iopub.execute_input":"2025-05-16T11:39:11.358711Z","iopub.status.idle":"2025-05-16T11:39:11.369674Z","shell.execute_reply.started":"2025-05-16T11:39:11.358684Z","shell.execute_reply":"2025-05-16T11:39:11.368909Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:11.370682Z","iopub.execute_input":"2025-05-16T11:39:11.370974Z","iopub.status.idle":"2025-05-16T11:39:11.464817Z","shell.execute_reply.started":"2025-05-16T11:39:11.370949Z","shell.execute_reply":"2025-05-16T11:39:11.464036Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"'''\nimport torch.optim as optim\n\nencoder = Encoder(len(src2idx), emb_dim, hidden_dim, cell_type, num_layers)\ndecoder = Decoder(len(trg2idx), emb_dim, hidden_dim, cell_type, num_layers)\nsos_idx = trg2idx[\"<sos>\"]\nmodel = Seq2Seq(encoder, decoder, DEVICE, sos_idx).to(DEVICE)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss(ignore_index=trg2idx[\"<pad>\"])\n'''\ndef tensor_from_word(word, mapping, add_eos=False):\n    indices = [mapping[ch] for ch in word]\n    if add_eos:\n        indices.append(mapping[\"<eos>\"])\n    return torch.tensor(indices, dtype=torch.long, device=DEVICE).unsqueeze(1)\n\n'''\nfor epoch in range(1, 6):\n    model.train()\n    epoch_loss = 0\n    train_correct = 0\n    train_total = 0\n\n    for src_word, trg_word in pairs:\n        src_tensor = tensor_from_word(src_word, src2idx)\n        trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n        optimizer.zero_grad()\n        output = model(src_tensor, trg_tensor)\n        output_dim = output.shape[-1]\n        loss = criterion(output.view(-1, output_dim), trg_tensor.view(-1))\n        loss.backward()\n        optimizer.step()\n        epoch_loss += loss.item()\n\n        # Training accuracy\n        pred_tokens = output.argmax(-1).view(-1)\n        true_tokens = trg_tensor.view(-1)\n        mask = true_tokens != trg2idx[\"<pad>\"]\n        correct = (pred_tokens == true_tokens) & mask\n        train_correct += correct.sum().item()\n        train_total += mask.sum().item()\n\n    # Validation\n    model.eval()\n    val_loss = 0\n    val_correct = 0\n    val_total = 0\n    with torch.no_grad():\n        for src_word, trg_word in val_pairs:\n            src_tensor = tensor_from_word(src_word, src2idx)\n            trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n            output = model(src_tensor, trg_tensor)\n            loss = criterion(output.view(-1, output.shape[-1]), trg_tensor.view(-1))\n            val_loss += loss.item()\n\n            pred_tokens = output.argmax(-1).view(-1)\n            true_tokens = trg_tensor.view(-1)\n            mask = true_tokens != trg2idx[\"<pad>\"]\n            correct = (pred_tokens == true_tokens) & mask\n            val_correct += correct.sum().item()\n            val_total += mask.sum().item()\n\n    train_acc = train_correct / train_total\n    val_acc = val_correct / val_total\n    print(f\"Epoch {epoch:3d} | Train Loss: {epoch_loss/len(pairs):.4f} | \"\n          f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_pairs):.4f} | Val Acc: {val_acc:.4f}\")\n\n'''","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:11.465814Z","iopub.execute_input":"2025-05-16T11:39:11.466160Z","iopub.status.idle":"2025-05-16T11:39:11.483348Z","shell.execute_reply.started":"2025-05-16T11:39:11.466128Z","shell.execute_reply":"2025-05-16T11:39:11.482351Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"'\\nfor epoch in range(1, 6):\\n    model.train()\\n    epoch_loss = 0\\n    train_correct = 0\\n    train_total = 0\\n\\n    for src_word, trg_word in pairs:\\n        src_tensor = tensor_from_word(src_word, src2idx)\\n        trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\\n\\n        optimizer.zero_grad()\\n        output = model(src_tensor, trg_tensor)\\n        output_dim = output.shape[-1]\\n        loss = criterion(output.view(-1, output_dim), trg_tensor.view(-1))\\n        loss.backward()\\n        optimizer.step()\\n        epoch_loss += loss.item()\\n\\n        # Training accuracy\\n        pred_tokens = output.argmax(-1).view(-1)\\n        true_tokens = trg_tensor.view(-1)\\n        mask = true_tokens != trg2idx[\"<pad>\"]\\n        correct = (pred_tokens == true_tokens) & mask\\n        train_correct += correct.sum().item()\\n        train_total += mask.sum().item()\\n\\n    # Validation\\n    model.eval()\\n    val_loss = 0\\n    val_correct = 0\\n    val_total = 0\\n    with torch.no_grad():\\n        for src_word, trg_word in val_pairs:\\n            src_tensor = tensor_from_word(src_word, src2idx)\\n            trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\\n            output = model(src_tensor, trg_tensor)\\n            loss = criterion(output.view(-1, output.shape[-1]), trg_tensor.view(-1))\\n            val_loss += loss.item()\\n\\n            pred_tokens = output.argmax(-1).view(-1)\\n            true_tokens = trg_tensor.view(-1)\\n            mask = true_tokens != trg2idx[\"<pad>\"]\\n            correct = (pred_tokens == true_tokens) & mask\\n            val_correct += correct.sum().item()\\n            val_total += mask.sum().item()\\n\\n    train_acc = train_correct / train_total\\n    val_acc = val_correct / val_total\\n    print(f\"Epoch {epoch:3d} | Train Loss: {epoch_loss/len(pairs):.4f} | \"\\n          f\"Train Acc: {train_acc:.4f} | Val Loss: {val_loss/len(val_pairs):.4f} | Val Acc: {val_acc:.4f}\")\\n\\n'"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"def beam_search(model, src_tensor, beam_size=3, max_len=30):\n    model.eval()\n    with torch.no_grad():\n        hidden = model.encoder(src_tensor)\n        hidden = model.adjust_hidden_for_decoder(hidden, model.decoder.rnn.num_layers)\n\n\n        if isinstance(hidden, tuple):\n            h, c = hidden\n            hidden = (\n                h[:model.decoder.rnn.num_layers],\n                c[:model.decoder.rnn.num_layers],\n            )\n        else:\n            hidden = hidden[:model.decoder.rnn.num_layers]\n\n        sequences = [([model.sos_idx], 0.0, hidden)]\n\n        for _ in range(max_len):\n            all_candidates = []\n            for seq, score, h in sequences:\n                input_step = torch.tensor([[seq[-1]]], device=model.device)\n                output, h_new = model.decoder(input_step, h)\n                probs = torch.log_softmax(output, dim=1)\n                topk = torch.topk(probs, beam_size)\n\n                for i in range(beam_size):\n                    token = topk.indices[0][i].item()\n                    token_score = topk.values[0][i].item()\n                    new_seq = seq + [token]\n                    all_candidates.append((new_seq, score + token_score, h_new))\n\n            sequences = sorted(all_candidates, key=lambda x: x[1], reverse=True)[:beam_size]\n\n            if all(seq[-1] == trg2idx[\"<eos>\"] for seq, _, _ in sequences):\n                break\n\n        best_seq = sequences[0][0][1:]  # remove <sos>\n        return \"\".join([idx2trg[i] for i in best_seq if i != trg2idx[\"<eos>\"]])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:11.484192Z","iopub.execute_input":"2025-05-16T11:39:11.484472Z","iopub.status.idle":"2025-05-16T11:39:11.497727Z","shell.execute_reply.started":"2025-05-16T11:39:11.484448Z","shell.execute_reply":"2025-05-16T11:39:11.497023Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"!pip install -q wandb\nimport wandb\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:11.498592Z","iopub.execute_input":"2025-05-16T11:39:11.498940Z","iopub.status.idle":"2025-05-16T11:39:18.669598Z","shell.execute_reply.started":"2025-05-16T11:39:11.498921Z","shell.execute_reply":"2025-05-16T11:39:18.668820Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"wandb.login(key='af7d7cf29d8954a13afb06c7a0d0c196c36ac51b')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:18.670422Z","iopub.execute_input":"2025-05-16T11:39:18.670767Z","iopub.status.idle":"2025-05-16T11:39:24.775063Z","shell.execute_reply.started":"2025-05-16T11:39:18.670746Z","shell.execute_reply":"2025-05-16T11:39:24.774250Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma24m003\u001b[0m (\u001b[33mma24m003-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"sweep_config = {\n    \"method\": \"bayes\",\n    \"metric\": {\"name\": \"val_acc\", \"goal\": \"maximize\"},\n    \"parameters\": {\n        \"emb_dim\": {\"values\": [16,32,64,256]},\n        \"hidden_dim\": {\"values\": [16,32,64,256]},\n        \"cell_type\": {\"values\": [\"RNN\",\"GRU\",\"LSTM\"]},\n        \"enc_layers\": {\"values\": [1,2,3]},\n        \"dec_layers\": {\"values\": [1, 2, 3]},\n        \"dropout\": {\"values\": [0,0.2, 0.3]},\n        \"beam_size\": {\"values\": [1, 3, 2]},\n        \"lr\": {\"values\": [0.001, 0.0005]}\n    }\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:24.775940Z","iopub.execute_input":"2025-05-16T11:39:24.776489Z","iopub.status.idle":"2025-05-16T11:39:24.782132Z","shell.execute_reply.started":"2025-05-16T11:39:24.776460Z","shell.execute_reply":"2025-05-16T11:39:24.781261Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def train_model(config=None):\n    with wandb.init(config=config) as run:\n        config = wandb.config\n\n        run.name = f\"emb{config.emb_dim}_hid{config.hidden_dim}_{config.cell_type}_enc{config.enc_layers}_dec{config.dec_layers}_drop{int(config.dropout*100)}_beam{config.beam_size}_lr{config.lr}\"\n\n        encoder = Encoder(len(src2idx), config.emb_dim, config.hidden_dim,\n                          config.cell_type, config.enc_layers, config.dropout)\n        decoder = Decoder(len(trg2idx), config.emb_dim, config.hidden_dim,\n                          config.cell_type, config.dec_layers, config.dropout)\n        model = Seq2Seq(encoder, decoder, DEVICE, sos_idx=trg2idx[\"<sos>\"]).to(DEVICE)\n\n        optimizer = optim.Adam(model.parameters(), lr=config.lr)\n        criterion = nn.CrossEntropyLoss(ignore_index=trg2idx[\"<pad>\"])\n        beam_size = config.get(\"beam_size\", 3)\n\n        for epoch in range(1, 6):\n            model.train()\n            total_loss = 0\n            train_correct = 0\n            train_total = 0\n\n            for src_word, trg_word in pairs:\n                src_tensor = tensor_from_word(src_word, src2idx)\n                trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n                optimizer.zero_grad()\n                output = model(src_tensor, trg_tensor, teacher_forcing_ratio=config.get(\"teacher_forcing_ratio\", 0.5))\n                loss = criterion(output.view(-1, output.size(-1)), trg_tensor.view(-1))\n                loss.backward()\n                optimizer.step()\n                total_loss += loss.item()\n\n                pred_tokens = output.argmax(-1).view(-1)\n                true_tokens = trg_tensor.view(-1)\n                mask = true_tokens != trg2idx[\"<pad>\"]\n                correct = (pred_tokens == true_tokens) & mask\n                train_correct += correct.sum().item()\n                train_total += mask.sum().item()\n\n            model.eval()\n            val_loss = 0\n            val_correct = 0\n            val_total = 0\n            exact_match_count = 0\n\n            with torch.no_grad():\n                for src_word, trg_word in val_pairs:\n                    src_tensor = tensor_from_word(src_word, src2idx)\n                    trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n                    output = model(src_tensor, trg_tensor, teacher_forcing_ratio=0.0)\n                    loss = criterion(output.view(-1, output.size(-1)), trg_tensor.view(-1))\n                    val_loss += loss.item()\n\n                    pred_tokens = output.argmax(-1).view(-1)\n                    true_tokens = trg_tensor.view(-1)\n                    mask = true_tokens != trg2idx[\"<pad>\"]\n                    correct = (pred_tokens == true_tokens) & mask\n                    val_correct += correct.sum().item()\n                    val_total += mask.sum().item()\n\n                    # Beam search for exact match accuracy\n                    pred_str = beam_search(model, src_tensor, beam_size=beam_size)\n                    if pred_str == trg_word:\n                        exact_match_count += 1\n\n            train_acc = train_correct / train_total\n            val_acc = val_correct / val_total\n            exact_match = exact_match_count / len(val_pairs)\n            \n            print(f\"Epoch {epoch:2d} | \"\n                  f\"Train Loss: {total_loss / len(pairs):.4f} | \"\n                  f\"Train Acc: {train_acc:.4f} | \"\n                  f\"Val Loss: {val_loss / len(val_pairs):.4f} | \"\n                  f\"Val Acc: {val_acc:.4f} | \"\n                  f\"Val Exact Match: {exact_match:.4f} | \"\n                  f\"Beam Size: {beam_size}\")\n\n            \n            wandb.log({\n                \"epoch\": epoch,\n                \"train_loss\": total_loss / len(pairs),\n                \"val_loss\": val_loss / len(val_pairs),\n                \"train_accuracy\": train_correct / train_total,\n                \"val_accuracy\": val_correct / val_total,\n                \"val_exact_match\": exact_match_count / len(val_pairs),\n                \"beam_size\": beam_size\n            })\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:24.783104Z","iopub.execute_input":"2025-05-16T11:39:24.783391Z","iopub.status.idle":"2025-05-16T11:39:24.807358Z","shell.execute_reply.started":"2025-05-16T11:39:24.783367Z","shell.execute_reply":"2025-05-16T11:39:24.806508Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"\nsweep_id = wandb.sweep(sweep_config, project=\"transliteration-sweep\")\nwandb.agent(sweep_id, function=train_model, count=10)\nwandb.finish()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T11:39:24.808184Z","iopub.execute_input":"2025-05-16T11:39:24.808523Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: 61b6oexp\nSweep URL: https://wandb.ai/ma24m003-iit-madras/transliteration-sweep/sweeps/61b6oexp\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1dsiwzgc with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: GRU\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 32\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlr: 0.001\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250516_113931-1dsiwzgc</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ma24m003-iit-madras/transliteration-sweep/runs/1dsiwzgc' target=\"_blank\">sweepy-sweep-1</a></strong> to <a href='https://wandb.ai/ma24m003-iit-madras/transliteration-sweep' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma24m003-iit-madras/transliteration-sweep/sweeps/61b6oexp' target=\"_blank\">https://wandb.ai/ma24m003-iit-madras/transliteration-sweep/sweeps/61b6oexp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ma24m003-iit-madras/transliteration-sweep' target=\"_blank\">https://wandb.ai/ma24m003-iit-madras/transliteration-sweep</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/ma24m003-iit-madras/transliteration-sweep/sweeps/61b6oexp' target=\"_blank\">https://wandb.ai/ma24m003-iit-madras/transliteration-sweep/sweeps/61b6oexp</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ma24m003-iit-madras/transliteration-sweep/runs/1dsiwzgc' target=\"_blank\">https://wandb.ai/ma24m003-iit-madras/transliteration-sweep/runs/1dsiwzgc</a>"},"metadata":{}},{"name":"stdout","text":"Epoch  1 | Train Loss: 2.7126 | Train Acc: 0.2595 | Val Loss: 2.4101 | Val Acc: 0.3048 | Val Exact Match: 0.0021 | Beam Size: 2\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"best_config = {\n    \"emb_dim\": 32,\n    \"hidden_dim\": 256,\n    \"cell_type\": \"LSTM\",\n    \"enc_layers\": 1,\n    \"dec_layers\": 1,\n    \"dropout\": 0,\n    \"beam_size\": 2,\n    \"lr\": 0.0005}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def best_train_model(config=None):\n    with wandb.init(config=config):\n        config = wandb.config\n\n        encoder = Encoder(len(src2idx), config.emb_dim, config.hidden_dim,\n                          config.cell_type, config.enc_layers, config.dropout)\n        decoder = Decoder(len(trg2idx), config.emb_dim, config.hidden_dim,\n                          config.cell_type, config.dec_layers, config.dropout)\n        model = Seq2Seq(encoder, decoder, DEVICE, sos_idx=trg2idx[\"<sos>\"]).to(DEVICE)\n\n        optimizer = optim.Adam(model.parameters(), lr=config.lr)\n        criterion = nn.CrossEntropyLoss(ignore_index=trg2idx[\"<pad>\"])\n        beam_size = config.get(\"beam_size\", 3)\n\n        for epoch in range(1, 6):\n            model.train()\n            total_loss = 0\n            train_correct = 0\n            train_total = 0\n\n            for src_word, trg_word in pairs:\n                src_tensor = tensor_from_word(src_word, src2idx)\n                trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n                optimizer.zero_grad()\n                output = model(src_tensor, trg_tensor, teacher_forcing_ratio=config.get(\"teacher_forcing_ratio\", 0.5))\n                loss = criterion(output.view(-1, output.size(-1)), trg_tensor.view(-1))\n                loss.backward()\n                optimizer.step()\n                total_loss += loss.item()\n\n                pred_tokens = output.argmax(-1).view(-1)\n                true_tokens = trg_tensor.view(-1)\n                mask = true_tokens != trg2idx[\"<pad>\"]\n                correct = (pred_tokens == true_tokens) & mask\n                train_correct += correct.sum().item()\n                train_total += mask.sum().item()\n\n            model.eval()\n            val_loss = 0\n            val_correct = 0\n            val_total = 0\n            exact_match_count = 0\n\n            with torch.no_grad():\n                for src_word, trg_word in val_pairs:\n                    src_tensor = tensor_from_word(src_word, src2idx)\n                    trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n                    output = model(src_tensor, trg_tensor, teacher_forcing_ratio=0.0)\n                    loss = criterion(output.view(-1, output.size(-1)), trg_tensor.view(-1))\n                    val_loss += loss.item()\n\n                    pred_tokens = output.argmax(-1).view(-1)\n                    true_tokens = trg_tensor.view(-1)\n                    mask = true_tokens != trg2idx[\"<pad>\"]\n                    correct = (pred_tokens == true_tokens) & mask\n                    val_correct += correct.sum().item()\n                    val_total += mask.sum().item()\n\n                    # Beam search for exact match accuracy\n                    pred_str = beam_search(model, src_tensor, beam_size=beam_size)\n                    if pred_str == trg_word:\n                        exact_match_count += 1\n\n            train_acc = train_correct / train_total\n            val_acc = val_correct / val_total\n            exact_match = exact_match_count / len(val_pairs)\n\n            print(f\"Epoch {epoch:2d} | \"\n                  f\"Train Loss: {total_loss / len(pairs):.4f} | \"\n                  f\"Train Acc: {train_acc:.4f} | \"\n                  f\"Val Loss: {val_loss / len(val_pairs):.4f} | \"\n                  f\"Val Acc: {val_acc:.4f} | \"\n                  f\"Val Exact Match: {exact_match:.4f} | \"\n                  f\"Beam Size: {beam_size}\")\n\n            wandb.log({\n                \"epoch\": epoch,\n                \"train_loss\": total_loss / len(pairs),\n                \"val_loss\": val_loss / len(val_pairs),\n                \"train_accuracy\": train_acc,\n                \"val_accuracy\": val_acc,\n                \"val_exact_match\": exact_match,\n                \"beam_size\": beam_size\n            })\n\n        return model  \n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = best_train_model(config=best_config)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntest_df = pd.read_csv(\"/kaggle/input/telugu-lexicon/te.translit.sampled.test.tsv\", sep=\"\\t\", header=None)\ntest_df.columns = [\"target\", \"source\", \"label\"]  # adjust if only 2 columns\ntest_df = test_df.dropna(subset=[\"source\", \"target\"])\ntest_df[\"source\"] = test_df[\"source\"].astype(str)\ntest_df[\"target\"] = test_df[\"target\"].astype(str)\ntest_pairs = list(zip(test_df[\"source\"], test_df[\"target\"]))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(test_pairs))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\ntest_correct = 0\ntest_total = 0\nexact_match_count = 0\nbeam_size = best_config[\"beam_size\"]\n\nwith torch.no_grad():\n    for src_word, trg_word in test_pairs:\n        src_tensor = tensor_from_word(src_word, src2idx)\n        trg_tensor = tensor_from_word(trg_word, trg2idx, add_eos=True)\n\n        output = model(src_tensor, trg_tensor, teacher_forcing_ratio=0.0)\n\n        # Character-level accuracy\n        pred_tokens = output.argmax(-1).view(-1)\n        true_tokens = trg_tensor.view(-1)\n        mask = true_tokens != trg2idx[\"<pad>\"]\n        correct = (pred_tokens == true_tokens) & mask\n        test_correct += correct.sum().item()\n        test_total += mask.sum().item()\n\n        # Word-level exact match via beam search\n        pred_str = beam_search(model, src_tensor, beam_size=beam_size)\n        if pred_str == trg_word:\n            exact_match_count += 1\n\ntest_char_acc = test_correct / test_total\ntest_exact_match = exact_match_count / len(test_pairs)\n\nprint(f\"Test Char Accuracy: {test_char_acc:.4f}\")\nprint(f\"Test Exact Match:  {test_exact_match:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tabulate import tabulate\n\ndef display_predictions(model, test_pairs, beam_size=3, max_samples=10):\n    model.eval()\n    table = []\n\n    with torch.no_grad():\n        sampled_pairs = random.sample(test_pairs, k=min(max_samples, len(test_pairs)))\n        for src_word, trg_word in sampled_pairs:\n            src_tensor = tensor_from_word(src_word, src2idx)\n            pred_str = beam_search(model, src_tensor, beam_size=beam_size)\n            match = \"✅\" if pred_str == trg_word else \"❌\"\n            table.append([src_word, pred_str, trg_word, match])\n\n    headers = [\"Input (Latin)\", \"Predicted (Telugu)\", \"Target (Telugu)\", \"Match\"]\n    print(tabulate(table, headers=headers, tablefmt=\"fancy_grid\"))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"display_predictions(model, test_pairs, beam_size=best_config[\"beam_size\"], max_samples=10)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}